---
title: "Creating a Unified AI Platform: How JetBrains Centralizes ML on Kubernetes with ZenML"
slug: "jetbrains"
draft: false

hub:
  cardTitle: "Creating a Unified AI Platform: How JetBrains Centralizes ML on Kubernetes with ZenML"
  order: 1
  logos:
    - url: "https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/b6111e84/jetbrains-min.svg"
      alt: "Jetbrains"

hero:
  logos:
    - url: "https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/b6111e84/jetbrains-min.svg"
      alt: "Jetbrains"

sidebar:
  company: "JetBrains"
  website:
    label: "jetbrains.com"
    href: "https://www.jetbrains.com"
  mlTeamSize: "44"
  industry: "Software"
  useCases:
    - "Kubernetes"
    - "Cross-platform"
    - "Dev to prod"

seo:
  title: "JetBrains and ZenML - Case Study"
  description: "Creating a Unified AI Platform: How JetBrains Centralizes ML on Kubernetes with ZenML"
  ogTitle: "JetBrains and ZenML - Case Study"
  ogDescription: "Creating a Unified AI Platform: How JetBrains Centralizes ML on Kubernetes with ZenML"
  ogImage: "https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/a55cb241/691d99c3c52d7a40b4a25ed8_jetbrains-case-study.png"

webflow:
  siteId: "64a817a2e7e2208272d1ce30"
  itemId: "static-page:case-study/jetbrains"
  exportedAt: "2026-02-11T06:26:00.000Z"
  source: live
---

<div class="uui-text-markdown-text w-richtext">
                <p><em>A phased migration from Kubeflow and Prefect OSS to a single platform now managing a 170% month‚Äëover‚Äëmonth execution growth and complex 3,000+ node agentic pipelines.</em></p>
                <h2><strong>üöÄ At a Glance: The JetBrains Transformation</strong></h2>
                <figure style="max-width:2472px" class="w-richtext-align-fullwidth w-richtext-figure-type-image">
                  <div><img src="https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/4d8e1599/jetbrains-summary.png" loading="lazy" alt="JetBrains and ZenML growth metrics April-October 2025: Active users 8‚Üí44 (450%), Unique Pipelines 3‚Üí49 (1,533%), Monthly Runs 150‚Üí2,765 (1,743%), Execution Time 845‚Üí247,966 min (29,250%)"></div>
                </figure>
                <ul role="list">
                  <li><strong>The Challenge:</strong> A ~200‚Äëperson AI organization‚Äîwith ~100 hands‚Äëon ML practitioners‚Äîwas fragmented across multiple systems, creating a high maintenance burden and blocking code reuse.</li>
                  <li><strong>The Solution:</strong> JetBrains adopted ZenML as its single, Kubernetes-native MLOps platform, enabling diverse teams to unify on one infrastructure.<strong>‚Äç</strong></li>
                  <li><strong>The Impact:</strong> Grew from 8 to 44 active users (450%) in 6 months. ZenML now efficiently manages a 170% month‚Äëover‚Äëmonth increase in total execution time (Sep‚ÜíOct 2025), runs complex 3,000+ node agentic pipelines, and has completely replaced Kubeflow for key workloads‚Äîstarting with the flagship pipeline‚Äîwhile consolidating work previously split between Kubeflow and Prefect OSS.</li>
                </ul>
              </div>
              <section class="uui-section_testimonial04">
                <div>
                  <div class="uui-container-large-22">
                    <div class="uui-testimonial04_component margin-bottom">
                      <h3 class="uui-heading-small text-weight-medium">"ZenML has helped us to boost the collaboration and best practices exchange, while keeping the infrastructure burden as low as possible for the MLEs."</h3>
                      <div class="uui-testimonial04_client">
                        <div class="uui-testimonial04_client-image-wrapper"><img src="https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/e47ff59e/vlad_jetbrains.jpg" loading="lazy" width="248" alt="Vladisnav Tankov" class="uui-testimonial04_client-image"></div>
                        <div class="uui-testimonial04_client-info">
                          <div class="uui-heading-tiny">Vladislav Tankov</div>
                          <div class="uui-text-size-medium">AI Director, JetBrains</div>
                        </div>
                      </div>
                    </div>
                  </div>
                </div>
              </section>
              <div class="uui-text-markdown-text w-richtext">
                <p><strong>üìä Key Metrics of Change</strong></p>
                <div class="w-embed">
                  <div class="table-container" style="width: 100%">
                    <table>
                      <thead>
                        <tr>
                          <th>Metric</th>
                          <th>April 2025 (Start)</th>
                          <th>July 2025 (3 Months)</th>
                          <th>October 2025 (6 Months)</th>
                          <th>Growth (Apr‚ÜíOct)</th>
                        </tr>
                      </thead>
                      <tbody>
                        <tr>
                          <td>Active Users</td>
                          <td>8</td>
                          <td>18</td>
                          <td>44</td>
                          <td>+450%</td>
                        </tr>
                        <tr>
                          <td>Unique Pipelines</td>
                          <td>3</td>
                          <td>39</td>
                          <td>49</td>
                          <td>+1,533%</td>
                        </tr>
                        <tr>
                          <td>Monthly Runs</td>
                          <td>150</td>
                          <td>1,070</td>
                          <td>2,765</td>
                          <td>+1,743%</td>
                        </tr>
                        <tr>
                          <td>Total Exec. Time (min)</td>
                          <td>845</td>
                          <td>86,300</td>
                          <td>247,966</td>
                          <td>+29,250%</td>
                        </tr>
                      </tbody>
                    </table>
                  </div>
                </div>
                
                <p><em>Note:</em> The <strong>+170%</strong> figure refers to the <strong>month‚Äëover‚Äëmonth</strong> change in total execution time from <strong>September to October 2025</strong>.</p>
                <h2><strong>The Challenge: When Enterprise Scale Creates Chaos</strong></h2>
                <h3><strong>The Orchestrator Sprawl</strong></h3>
                <p>Before standardizing, JetBrains' MLOps team was managing a fragmented and costly collection of tools. This was not only inefficient but was creating a significant and growing maintenance burden at the same time. Different teams used different solutions for similar problems‚Äî<strong>Prefect OSS</strong> for classical ML and lightweight training, <strong>Kubeflow</strong> for LLM evaluation and data prep, and raw <strong>Kubernetes scripts</strong> for LLM training‚Äîwhich created a high-overhead environment where infrastructure support was fractured and best practices were impossible to enforce.</p>
                <h3><strong>The Collaboration Crisis</strong></h3>
                <p>This technical fragmentation created deep organizational silos. With a ~200‚Äëperson AI organization‚Äîand around 100 hands‚Äëon ML practitioners‚Äîthere was no unified platform to track models from training to evaluation, making lineage and reproducibility a manual, detective‚Äëlike process. As a result, code reuse was nearly impossible, and valuable time was lost as teams independently solved the same problems, unable to build on each other's work.</p>
                <h3><strong>The Department Dilemma</strong></h3>
                <p>Initially, the MLOps team‚Äôs mandate was to support multiple teams within a single department. Even within that boundary, teams followed entirely different rules and architectural patterns‚Äîfrom monorepos to dedicated repositories‚Äîmaking a one‚Äësize‚Äëfits‚Äëall solution unrealistic. This diversity of environments and requirements made a one-size-fits-all solution impossible and which meant the current model was fundamentally unsustainable.</p>
                <figure style="max-width:2432pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image">
                  <div><img src="https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/1829db9b/jetbrains-before_after.png" loading="lazy" alt="Comparison diagram showing fragmented tools before with high maintenance burden, low reuse, and limited lineage issues, versus a unified workflow using ZenML Unified Platform with shared artifacts, supporting models research, validation, and data logs, marked as vendor agnostic and Kubernetes native."></div>
                </figure>
                <h2><strong>The Solution: Develop Locally, Scale on Kubernetes</strong></h2>
                <h3><strong>Why ZenML Won the Evaluation</strong></h3>
                <p>JetBrains ran a market-wide evaluation to find one platform that satisfied both advanced and casual users without increasing infra overhead. ZenML stood out on developer experience and platform fundamentals:</p>
                <ul role="list">
                  <li><strong>Simple, Pythonic SDK and ease of use</strong>: Teams define pipelines as plain Python with minimal boilerplate and sensible defaults. This made it straightforward to move from scripts/notebooks and previously environment‚Äëlocked pipes to reproducible pipelines and accelerated onboarding.</li>
                  <li><strong>Proper artifact versioning and lineage</strong>: Outputs are versioned by default and lineage is tracked across steps and runs, enabling reliable reproducibility, side‚Äëby‚Äëside comparisons, and auditability. Shared artifacts also make reuse across teams practical.</li>
                  <li><strong>Run locally, scale on Kubernetes unchanged</strong>: The same code runs on a laptop for fast iteration and on internal GKE and external GPU Kubernetes clusters for scale. Local/inline runtimes tighten the dev loop and reduce cold‚Äëstart overhead.</li>
                  <li><strong>Incremental adoption with pragmatic migration</strong>: Teams migrated pipeline‚Äëby‚Äëpipeline‚Äîno big‚Äëbang rewrite. Portions of existing training/eval code could often be wrapped as steps with some refactoring, while tightly coupled pipelines required deeper changes. Existing data stores and surrounding services were reused where feasible.</li>
                  <li><strong>Kubernetes‚Äëfirst architecture</strong>: Native Kubernetes integration fits their internal and external clusters, supporting GPU workloads, namespace isolation, secrets management, and enterprise networking patterns.</li>
                  <li><strong>Vendor‚Äëagnostic (no cloud lock‚Äëin)</strong>: Works across clouds and on‚Äëprem, aligning with JetBrains‚Äô strategy to avoid provider‚Äëspecific MLOps stacks.</li>
                  <li><strong>Cost‚Äëeffective enterprise footprint</strong>: Consolidates multiple orchestrators and homegrown glue into one platform, reducing maintenance burden while improving governance and observability.</li>
                </ul>
                <figure style="max-width:2568pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image">
                  <div><img src="https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/461b2150/jetbrains-stack.png" loading="lazy" alt="Diagram showing ZenML's orchestration, artifact versioning, secrets management, and projects/permissions connecting a developer to internal GKE and external GPU Kubernetes clusters, plus artifact store and data/logs."></div>
                </figure>
                <h3><strong>The Phased Implementation Journey</strong></h3>
                <p>Implementation was a phased and strategic journey, not a "big bang" migration. After a successful proof-of-concept in early 2025, the JetBrains teams with support from the MLOps team began methodically migrating workloads and implementing new complex pipelines for agent use-cases and beyond.</p>
                <p>They strategically targeted their most complex and widely-used <strong>"flagman" (flagship) pipeline</strong> from Kubeflow first. By proving the platform's value on this critical, high-visibility workload, they established best practices and built internal confidence. This strategy was a clear success, paving the way for wider adoption that grew from just 8 monthly active users in April to 44 by October.</p>
                <h3><strong>An Architecture for Enterprise Scale</strong></h3>
                <p>The team now manages a highly sophisticated architecture on ZenML, tailored to their enterprise scale.</p>
                <ul role="list">
                  <li><strong>Logical Workload Separation:</strong> They organize work into distinct ZenML projects (e.g., Models R&amp;D, Validation, Data/Logs) to cleanly manage the lifecycle and permissions for different teams.</li>
                  <li><strong>Advanced Orchestration:</strong> More advanced teams are able to work with more complex architectures to dynamically orchestrate complex GPU workloads.</li>
                  <li><strong>Proven for AI:</strong> The platform has proven it can handle this complexity, successfully running massive agentic AI pipelines with <strong>over 3,000 nodes</strong> in a single graph and multiple such graphs at the same time. One of these is used for evaluating their coding agent and runs popular agent benchmarks against their system to get a sense of how well it performs.</li>
                </ul>
                <h2><strong>The Results: Compound Growth and Stability</strong></h2>
                <p>The successful migration and internal development efforts have translated into measurable, compounding gains for JetBrains. The platform's stability and feature set have become a powerful draw for internal teams.</p>
                <h3><strong>Explosive and Organic Adoption</strong></h3>
                <p>The strongest proof of success has been the platform's rapid, organic adoption following internal advocacy. In a single month (September to October 2025), the number of monthly active users grew by <strong>63%</strong>, driven by word-of-mouth and visible team successes. Concretely, unique monthly active users grew from <strong>27 to 44</strong> between September and October 2025 (+63% month‚Äëover‚Äëmonth), as additional teams started running real workloads. This demand is widespread, with a planned internal workshop on ML workflows attracting <strong>over 150 invites</strong> from across the organization, signaling massive interest in the new, standardized approach.</p>
                <h3><strong>Technical and Migration Wins</strong></h3>
                <p>With a unified platform, JetBrains has unlocked significant technical victories. The MLOps team is successfully migrating complex workloads off of Kubeflow and Prefect OSS, eliminating a major maintenance burden and unifying their infrastructure. New platform capabilities like inline runtimes shorten feedback loops for simple pipelines by skipping per‚Äëstep container cold starts; the orchestrator still initializes as usual. Combined with completed stability improvements, this has shifted internal perception from early ‚Äúlow‚Äëmaturity‚Äù concerns to a stable, production‚Äëgrade platform with good standing internally.</p>
                <figure style="max-width:3414pxpx" class="w-richtext-align-fullwidth w-richtext-figure-type-image">
                  <div><img src="https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/a7dcf8ee/jetbrains-timeline.png" loading="lazy" alt="Timeline from January to October 2025 showing phases: POC validated; Kubeflow pipeline migration; replacement with incremental wrapping; inline runtimes introduced; 63% MAU growth and 170% execution time improvement; and scaling to 150+ workshop invites and ZenML as default for new ML projects, with user growth from 8 to 44."></div>
                </figure>
                <h2><strong>Looking Forward: A Strategic Partnership for the Next Wave of AI</strong></h2>
                <p>The collaboration between JetBrains and ZenML has evolved from addressing initial infrastructure challenges to enabling future innovation. With a stable foundation, the focus is now on scaling the platform's impact across the entire company.</p>
                <h3><strong>Scaling Knowledge</strong></h3>
                <p>The partnership now includes deep collaboration on scaling best practices. Jointly-planned workshops for JetBrains' 150-person ML organization are designed to transfer knowledge efficiently, ensuring that teams can not only use the platform but also leverage its most advanced capabilities for complex AI workloads.</p>
                <h3><strong>Scaling Adoption</strong></h3>
                <p>ZenML is now the standard default platform for new ML projects at JetBrains, reducing the overhead of selecting and configuring disparate frameworks. Adoption and momentum continues to expand, with a large team currently onboarding. This promises even more significant growth in the coming months.</p>
                <h3><strong>Scaling Innovation</strong></h3>
                <p>With a stable and scalable foundation, the partnership is now focused on unlocking the next frontier of innovation. The MLOps team is no longer just managing complexity; they‚Äôre enabling simplicity at scale. The unified platform gives them the capacity to explore and productionize sophisticated agentic AI workloads and advanced model architectures, positioning JetBrains to stay at the vanguard of AI development.</p>
              </div>
