---
title: "AI-Powered Fax Processing Automation for Healthcare Referrals"
slug: "ai-powered-fax-processing-automation-for-healthcare-referrals"
draft: false
webflow:
  siteId: "64a817a2e7e2208272d1ce30"
  itemId: "687dffb7cd4a6af84b69fcba"
  exportedAt: "2026-02-11T10:23:34.071Z"
  source: "live"
  lastPublished: "2025-12-23T12:21:17.478Z"
  lastUpdated: "2025-12-18T17:15:31.669Z"
  createdOn: "2025-07-21T08:52:07.573Z"
llmopsTags:
  - "healthcare"
  - "document-processing"
  - "unstructured-data"
  - "high-stakes-application"
  - "regulatory-compliance"
  - "prompt-engineering"
  - "rag"
  - "model-optimization"
  - "error-handling"
  - "chunking"
  - "system-prompts"
  - "kubernetes"
  - "postgresql"
  - "cicd"
  - "monitoring"
  - "orchestration"
  - "open-source"
  - "scaling"
  - "microservices"
  - "databricks"
  - "openai"
  - "microsoft-azure"
company: "Providence"
summary: "Providence Health System automated the processing of over 40 million annual faxes using GenAI and MLflow on Databricks to transform manual referral workflows into real-time automated triage. The system combines OCR with GPT-4.0 models to extract referral data from diverse document formats and integrates seamlessly with Epic EHR systems, eliminating months-long backlogs and freeing clinical staff to focus on patient care across 1,000+ clinics."
link: "https://www.databricks.com/blog/transforming-patient-referrals-providence-uses-databricks-mlflow-accelerate-automation"
year: 2025
seo:
  title: "Providence: AI-Powered Fax Processing Automation for Healthcare Referrals - ZenML LLMOps Database"
  description: "Providence Health System automated the processing of over 40 million annual faxes using GenAI and MLflow on Databricks to transform manual referral workflows into real-time automated triage. The system combines OCR with GPT-4.0 models to extract referral data from diverse document formats and integrates seamlessly with Epic EHR systems, eliminating months-long backlogs and freeing clinical staff to focus on patient care across 1,000+ clinics."
  canonical: "https://www.zenml.io/llmops-database/ai-powered-fax-processing-automation-for-healthcare-referrals"
  ogTitle: "Providence: AI-Powered Fax Processing Automation for Healthcare Referrals - ZenML LLMOps Database"
  ogDescription: "Providence Health System automated the processing of over 40 million annual faxes using GenAI and MLflow on Databricks to transform manual referral workflows into real-time automated triage. The system combines OCR with GPT-4.0 models to extract referral data from diverse document formats and integrates seamlessly with Epic EHR systems, eliminating months-long backlogs and freeing clinical staff to focus on patient care across 1,000+ clinics."
---

Providence Health System represents one of the largest nonprofit health systems in the United States, serving vulnerable communities through 51 hospitals, over 1,000 outpatient clinics, and more than 130,000 caregivers across seven states. Their case study demonstrates a sophisticated application of LLMOps principles to solve a critical healthcare workflow challenge: the automated processing of massive volumes of referral faxes that previously required manual intervention and created significant care delays.

The core problem facing Providence was the overwhelming volume of healthcare communications that still rely heavily on fax technology despite digital transformation efforts. The organization processes more than 40 million faxes annually, totaling over 160 million pages, with a significant portion requiring manual review and transcription into their Epic electronic health record (EHR) system. This manual process created multi-month backlogs, delayed patient care, and consumed valuable clinical staff time that could be better spent on direct patient care activities.

From an LLMOps perspective, Providence's approach exemplifies several key principles of production AI deployment. Their technical architecture centers on the Databricks Data Intelligence Platform, specifically leveraging MLflow for experiment management and model lifecycle operations. This choice reflects a mature understanding of the need for systematic experimentation when dealing with the inherent variability and complexity of unstructured healthcare documents.

The experimentation framework built around MLflow addresses several critical LLMOps challenges. Providence uses parameterized jobs to systematically sweep across combinations of OCR models, prompt templates, and other hyperparameters. This approach allows them to manage the complexity of optimizing multiple components simultaneously - from optical character recognition tools to language model prompts. The parameterized job framework enables dynamic input configuration at runtime, making their experimental pipeline both flexible and reusable through CI/CD integration that produces YAML configuration files for large-scale testing.

Central to their LLMOps strategy is comprehensive experiment tracking and logging through MLflow. This provides the team with clear visibility into model performance across different document types and referral scenarios, enabling efficient comparison of results without duplicating experimental effort. The centralized logging capability supports deeper evaluation of model behavior, which is particularly crucial given the diversity of referral forms and the strict compliance requirements within heavily regulated EHR environments like Epic.

Providence's use of historical data for simulation represents another sophisticated LLMOps practice. By leveraging existing fax data to simulate downstream outcomes, they can refine their models before production deployment, significantly reducing risk and accelerating the deployment cycle. This is particularly important in healthcare settings where errors can have significant patient care implications and where integration with established systems like Epic requires rigorous validation.

The technical stack demonstrates a thoughtful integration of multiple AI technologies within a production environment. While Azure AI Document Intelligence handles OCR processing and OpenAI's GPT-4.0 models perform information extraction, the real engineering value comes from the MLflow-orchestrated pipeline that automates what would otherwise be manual and fragmented development processes. This unified approach through the Databricks platform enables the transformation of raw fax documents through experimentation with different AI techniques and validation of outputs with both speed and confidence.

The integration requirements with Epic EHR systems add another layer of complexity to the LLMOps implementation. All extracted referral data must be seamlessly formatted, validated, and securely delivered to the existing healthcare infrastructure. Databricks plays a critical role in pre-processing and normalizing this information before handoff to the EHR system, requiring careful attention to data quality and format consistency.

Providence's broader technical infrastructure includes Azure Kubernetes Service (AKS) for containerized deployment, Azure Search to support retrieval-augmented generation (RAG) workflows, and Postgres for structured storage. This multi-service architecture requires sophisticated orchestration and monitoring capabilities to ensure reliable operation at the scale of 40 million documents annually. The team is also actively exploring Mosaic AI for RAG and Model Serving to enhance accuracy, scalability, and responsiveness of their AI solutions, indicating continued evolution of their LLMOps practices.

The production deployment strategy addresses several key LLMOps considerations around scalability and reliability. Moving from manual processing to real-time automation of 40 million annual faxes requires robust infrastructure capable of handling peak loads and maintaining consistent performance. The shift from months-long backlogs to real-time processing represents a significant operational transformation that required careful attention to system reliability and error handling.

One of the most interesting aspects of Providence's LLMOps implementation is their approach to handling the inherent variability in healthcare workflows. The lack of standardization between clinics, roles, and individuals creates significant challenges for defining universal automation pipelines or creating test scenarios that reflect real-world complexity. Their experimentation framework addresses this by enabling rapid iteration across different configurations and validation against diverse document types and workflow patterns.

The diversity of input documents - from handwritten notes to typed PDFs - creates a wide range of processing challenges that require sophisticated prompt engineering and model tuning. Providence's systematic approach to hyperparameter optimization through MLflow enables them to handle this complexity more effectively than ad-hoc manual tuning approaches would allow.

From a business impact perspective, the LLMOps implementation has delivered significant operational improvements. The elimination of two to three-month backlogs in some regions directly impacts patient care timelines, while the automation of repetitive document processing frees clinical staff to focus on higher-value activities. The system-wide efficiency gains scale across Providence's 1,000+ outpatient clinics, supporting their mission to provide timely, coordinated care at scale.

The case study also highlights important considerations around change management and workflow transformation in healthcare settings. The transition from manual to automated processing requires careful consideration of existing staff workflows and training needs, as well as integration with established clinical practices and compliance requirements.

Providence's approach demonstrates mature LLMOps practices including systematic experimentation, comprehensive monitoring and logging, automated testing and validation, and seamless integration with existing enterprise systems. Their use of MLflow for experiment management and model lifecycle operations provides a solid foundation for continued iteration and improvement of their AI-powered automation systems. The case represents a successful example of applying LLMOps principles to solve real-world healthcare challenges at enterprise scale, with measurable impacts on operational efficiency and patient care delivery.