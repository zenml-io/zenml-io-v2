---
title: "Large Recommender Models: Adapting Gemini for YouTube Video Recommendations"
slug: "large-recommender-models-adapting-gemini-for-youtube-video-recommendations"
draft: false
webflow:
  siteId: "64a817a2e7e2208272d1ce30"
  itemId: "687e00b45e7defa43c95d297"
  exportedAt: "2026-02-11T10:23:34.071Z"
  source: "live"
  lastPublished: "2025-12-23T12:21:17.478Z"
  lastUpdated: "2025-12-18T17:15:29.110Z"
  createdOn: "2025-07-21T08:56:20.710Z"
llmopsTags:
  - "content-moderation"
  - "classification"
  - "summarization"
  - "multi-modality"
  - "unstructured-data"
  - "realtime-application"
  - "structured-output"
  - "embeddings"
  - "prompt-engineering"
  - "few-shot"
  - "semantic-search"
  - "vector-search"
  - "model-optimization"
  - "knowledge-distillation"
  - "instruction-tuning"
  - "token-optimization"
  - "cost-optimization"
  - "chunking"
  - "system-prompts"
  - "tensorflow"
  - "pytorch"
  - "fastapi"
  - "cache"
  - "monitoring"
  - "scaling"
  - "serverless"
  - "microservices"
  - "google-gcp"
company: "Google / YouTube"
summary: "YouTube developed Large Recommender Models (LRM) by adapting Google's Gemini LLM for video recommendations, addressing the challenge of serving personalized content to billions of users. The solution involved creating semantic IDs to tokenize videos, continuous pre-training to teach the model both English and YouTube-specific video language, and implementing generative retrieval systems. While the approach delivered significant improvements in recommendation quality, particularly for challenging cases like new users and fresh content, the team faced substantial serving cost challenges that required 95%+ cost reductions and offline inference strategies to make production deployment viable at YouTube's scale."
link: "https://www.youtube.com/watch?v=LxQsQ3vZDqo"
year: 2025
seo:
  title: "Google / YouTube: Large Recommender Models: Adapting Gemini for YouTube Video Recommendations - ZenML LLMOps Database"
  description: "YouTube developed Large Recommender Models (LRM) by adapting Google's Gemini LLM for video recommendations, addressing the challenge of serving personalized content to billions of users. The solution involved creating semantic IDs to tokenize videos, continuous pre-training to teach the model both English and YouTube-specific video language, and implementing generative retrieval systems. While the approach delivered significant improvements in recommendation quality, particularly for challenging cases like new users and fresh content, the team faced substantial serving cost challenges that required 95%+ cost reductions and offline inference strategies to make production deployment viable at YouTube's scale."
  canonical: "https://www.zenml.io/llmops-database/large-recommender-models-adapting-gemini-for-youtube-video-recommendations"
  ogTitle: "Google / YouTube: Large Recommender Models: Adapting Gemini for YouTube Video Recommendations - ZenML LLMOps Database"
  ogDescription: "YouTube developed Large Recommender Models (LRM) by adapting Google's Gemini LLM for video recommendations, addressing the challenge of serving personalized content to billions of users. The solution involved creating semantic IDs to tokenize videos, continuous pre-training to teach the model both English and YouTube-specific video language, and implementing generative retrieval systems. While the approach delivered significant improvements in recommendation quality, particularly for challenging cases like new users and fresh content, the team faced substantial serving cost challenges that required 95%+ cost reductions and offline inference strategies to make production deployment viable at YouTube's scale."
---

## YouTube's Large Recommender Models: A Production-Scale LLMOps Case Study

YouTube's implementation of Large Recommender Models (LRM) represents one of the most ambitious production deployments of LLMs for recommendation systems at consumer internet scale. The project demonstrates how a major technology company adapted a general-purpose language model (Gemini) for a highly specific domain application serving billions of users daily.

### The Business Context and Problem

YouTube operates one of the world's largest consumer applications with billions of daily active users, where the vast majority of watch time is driven by their recommendation system. The platform serves recommendations across multiple surfaces including the home feed, watch next suggestions, shorts, and personalized search results. The scale of the problem is staggering: YouTube hosts over 20 billion videos with millions added daily, requiring the system to quickly understand and recommend fresh content within minutes or hours of upload.

The speaker argues that while much attention focuses on LLMs transforming search (citing Google Search's evolution, ChatGPT, and Perplexity), recommendation systems represent a potentially larger but underappreciated application area for LLMs in consumer products. This perspective is particularly interesting given that recommendation improvements are largely invisible to users - they simply experience better content feeds without knowing whether an LLM inference occurred.

### Technical Architecture and Implementation

#### Semantic ID Development

The foundation of YouTube's LRM system is their innovative "Semantic ID" approach to video tokenization. Traditional LLMs tokenize text into linguistic units, but YouTube needed to tokenize videos themselves. Their solution extracts multiple features from each video including title, description, transcript, audio, and video frame-level data, combines these into multi-dimensional embeddings, and then uses RQ-VQE (Residual Quantization Vector Quantization) to assign each video a semantic token.

This creates what the team describes as "atomic units for a new language of YouTube videos." The tokenization is hierarchical and semantically meaningful - for example, the first token might represent broad categories like music, gaming, or sports, with subsequent tokens providing increasing specificity (sports → volleyball → specific volleyball videos). This approach moves beyond hash-based tokenization to create semantically meaningful representations that can capture relationships between videos.

#### Model Adaptation Process

YouTube's approach involves a two-step adaptation of the base Gemini model. First, they perform continued pre-training to teach the model to understand both English and their new "YouTube language." This involves linking text and Semantic IDs through training tasks where the model learns to predict video titles, creators, and topics when given a semantic ID token.

The second step uses YouTube's extensive engagement data - the corpus of user viewing patterns and video sequences. They train the model on masked prediction tasks where users' watch sequences are provided with some videos masked, teaching the model to predict what videos users watched together. This enables the model to understand video relationships based on actual user behavior rather than just content similarity.

The result is described as a "bilingual LLM" that can reason across both English and YouTube's video space. Demonstrations show the model can understand that a tennis highlights video is interesting to tennis fans because it's about Wimbledon, an F1 video appeals to racing fans due to the Spanish Grand Prix content, and can make similar inferences about AI content appealing to technology enthusiasts.

#### Generative Retrieval Implementation

For production deployment, YouTube implements generative retrieval by constructing personalized prompts for each user. These prompts include demographic information (age, gender, location, device), current context (the video being watched), and rich watch history (last 100 videos, engagement depth, comments, subscriptions). The LRM then generates video recommendations as semantic ID tokens.

The system shows particular strength in "hard" recommendation cases - situations where traditional collaborative filtering struggles. For example, when watching Olympic highlights, the pre-LRM system might recommend other men's track races, while LRM can identify unique connections between user demographics and watch history to recommend related women's races that weren't previously surfaced.

### Production Challenges and Solutions

#### Scale and Cost Management

The most significant challenge in deploying LRM at YouTube's scale was serving cost. Despite the model's impressive capabilities - described as very powerful, quick to learn, and training data efficient - the computational costs of serving transformer-based models to billions of users proved initially prohibitive. The team achieved over 95% cost reductions through various optimization techniques to make production deployment viable.

One innovative solution was converting personalized recommendation into an offline problem. By removing personalized aspects from prompts and pre-computing recommendations for popular videos, they created offline recommendation tables. While unpersonalized models typically underperform personalized ones, the LRM's training from a large checkpoint provided sufficiently differentiated recommendations to make this approach viable. This allowed simple lookup operations at serving time, dramatically reducing computational requirements.

#### Continuous Learning Requirements

Unlike traditional LLM pre-training cycles that might occur every 3-6 months, YouTube's recommendation system requires continuous pre-training on the order of days or hours. The freshness requirement is critical - when Taylor Swift releases a new music video, the system must understand and recommend it within minutes or hours, or users will be dissatisfied. This creates a much more demanding operational environment compared to general-purpose LLMs.

The vocabulary challenge is also more dynamic than traditional language models. While English adds roughly 1,000 new words annually to a 100,000-word vocabulary, YouTube adds millions of new videos daily to a corpus of 20 billion videos. Missing a few new English words might affect some pop culture references, but failing to quickly understand and recommend trending video content directly impacts user satisfaction.

#### Model Size and Latency Constraints

YouTube had to focus on smaller, more efficient models rather than the full Gemini Pro, using Gemini Flash and even smaller checkpoints to meet latency and scale requirements for billions of daily active users. This represents a common LLMOps challenge where the most capable models may not be deployable at required scale and cost constraints.

### Production Results and Impact

While the speaker couldn't share specific metrics, they indicated that LRM represents "the biggest improvement to recommendation quality we've seen in the last few years," suggesting significant business impact. The system has been launched in production for retrieval and is being extensively experimented with for ranking applications.

The improvements are particularly notable for challenging recommendation scenarios: new users with limited watch history, fresh content with minimal engagement data, and situations requiring understanding of complex user-content relationships that traditional collaborative filtering misses.

### Technical Innovations and LLMOps Insights

#### Domain-Specific Language Creation

YouTube's approach of creating a domain-specific language through semantic tokenization represents an innovative LLMOps pattern. Rather than trying to force existing language model paradigms onto video recommendation, they created new atomic units that preserve semantic relationships while enabling transformer architectures to reason about video content.

#### Balancing Multiple Capabilities

The team discovered challenges in maintaining both English language capabilities and semantic ID reasoning abilities. Overtraining on semantic ID tasks caused the model to "forget" English, potentially reasoning in intermediate layers before outputting semantic tokens. They're exploring mixture of experts architectures where some experts retain text capabilities while others focus on semantic ID understanding.

#### Cold Start Solutions

The unsupervised nature of semantic ID training provides natural cold start capabilities. The system learns concepts like sports versus entertainment without explicit labeling, and the semantic meaningfulness helps with fresh content that lacks engagement history. Performance for newly uploaded videos (within days or weeks) shows significant improvement compared to traditional approaches.

### Future Directions and Implications

The speaker envisions evolution from LLMs augmenting recommendations invisibly to users directly interacting with recommendation systems through natural language. Future capabilities might include users steering recommendations toward personal goals, recommenders explaining their suggestions, and blurred lines between search and recommendation.

A more speculative future direction involves recommending personalized versions of content or even generating content specifically for individual users, moving from content recommendation to content creation.

### LLMOps Best Practices and Lessons

YouTube's experience provides several key insights for LLMOps practitioners:

**Domain Adaptation Strategy**: The three-step recipe of tokenizing domain content, adapting the LLM for bilingual capability, and creating task-specific models through prompting provides a framework for adapting general-purpose LLMs to specific domains.

**Cost-Performance Tradeoffs**: Even when models show superior quality, serving costs can be prohibitive at scale. Creative solutions like offline inference and pre-computation may be necessary to balance quality improvements with operational constraints.

**Continuous Learning Requirements**: Domain-specific applications may require much more frequent model updates than general-purpose LLMs, creating additional operational complexity.

**Scale Considerations**: The most capable models may not be deployable at required scale, necessitating careful model size selection and optimization.

This case study demonstrates that while LLMs can provide significant quality improvements for recommendation systems, successful production deployment requires sophisticated engineering solutions to address cost, scale, and operational challenges. The approach shows how major technology companies are moving beyond simple API calls to foundation models toward deep integration and adaptation of LLM capabilities for specific use cases.