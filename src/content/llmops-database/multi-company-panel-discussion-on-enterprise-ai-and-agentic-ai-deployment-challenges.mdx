---
title: "Multi-Company Panel Discussion on Enterprise AI and Agentic AI Deployment Challenges"
slug: "multi-company-panel-discussion-on-enterprise-ai-and-agentic-ai-deployment-challenges"
draft: false
webflow:
  siteId: "64a817a2e7e2208272d1ce30"
  itemId: "693bdd2ee7efbbe5dbf75e29"
  exportedAt: "2026-02-11T13:30:32.135Z"
  source: "live"
  lastPublished: "2025-12-23T12:21:17.478Z"
  lastUpdated: "2025-12-18T17:35:06.568Z"
  createdOn: "2025-12-12T09:15:26.352Z"
llmopsTags:
  - "customer-support"
  - "document-processing"
  - "data-integration"
  - "poc"
  - "question-answering"
  - "chatbot"
  - "data-analysis"
  - "prompt-engineering"
  - "human-in-the-loop"
  - "multi-agent-systems"
  - "agent-based"
  - "rag"
  - "embeddings"
  - "semantic-search"
  - "error-handling"
  - "evals"
  - "mcp"
  - "crewai"
  - "langchain"
  - "security"
  - "guardrails"
  - "api-gateway"
  - "databases"
  - "monitoring"
  - "documentation"
  - "open-source"
  - "anthropic"
  - "openai"
  - "google-gcp"
  - "amazon-aws"
  - "meta"
industryTags: "tech"
company: "Glean / Deloitte / Docusign"
summary: "This panel discussion at AWS re:Invent brings together practitioners from Glean, Deloitte, and DocuSign to discuss the practical realities of deploying AI and agentic AI systems in enterprise environments. The panelists explore challenges around organizational complexity, data silos, governance, agent creation and sharing, value measurement, and the tension between autonomous capabilities and human oversight. Key themes include the need for cross-functional collaboration, the importance of security integration from day one, the difficulty of measuring AI-driven productivity gains, and the evolution from individual AI experimentation to governed enterprise-wide agent deployment. The discussion emphasizes that successful AI transformation requires reimagining workflows rather than simply bolting AI onto legacy systems, and that business value should drive technical decisions rather than focusing solely on which LLM model to use."
link: "https://www.youtube.com/watch?v=ObAJIOJrcK8"
year: 2025
seo:
  title: "Glean / Deloitte / Docusign: Multi-Company Panel Discussion on Enterprise AI and Agentic AI Deployment Challenges - ZenML LLMOps Database"
  description: "This panel discussion at AWS re:Invent brings together practitioners from Glean, Deloitte, and DocuSign to discuss the practical realities of deploying AI and agentic AI systems in enterprise environments. The panelists explore challenges around organizational complexity, data silos, governance, agent creation and sharing, value measurement, and the tension between autonomous capabilities and human oversight. Key themes include the need for cross-functional collaboration, the importance of security integration from day one, the difficulty of measuring AI-driven productivity gains, and the evolution from individual AI experimentation to governed enterprise-wide agent deployment. The discussion emphasizes that successful AI transformation requires reimagining workflows rather than simply bolting AI onto legacy systems, and that business value should drive technical decisions rather than focusing solely on which LLM model to use."
  canonical: "https://www.zenml.io/llmops-database/multi-company-panel-discussion-on-enterprise-ai-and-agentic-ai-deployment-challenges"
  ogTitle: "Glean / Deloitte / Docusign: Multi-Company Panel Discussion on Enterprise AI and Agentic AI Deployment Challenges - ZenML LLMOps Database"
  ogDescription: "This panel discussion at AWS re:Invent brings together practitioners from Glean, Deloitte, and DocuSign to discuss the practical realities of deploying AI and agentic AI systems in enterprise environments. The panelists explore challenges around organizational complexity, data silos, governance, agent creation and sharing, value measurement, and the tension between autonomous capabilities and human oversight. Key themes include the need for cross-functional collaboration, the importance of security integration from day one, the difficulty of measuring AI-driven productivity gains, and the evolution from individual AI experimentation to governed enterprise-wide agent deployment. The discussion emphasizes that successful AI transformation requires reimagining workflows rather than simply bolting AI onto legacy systems, and that business value should drive technical decisions rather than focusing solely on which LLM model to use."
---

## Overview

This panel discussion provides a comprehensive exploration of real-world LLMOps challenges from three distinct perspectives: Glean (an AI platform provider), Deloitte (a consulting firm implementing AI across multiple clients), and DocuSign (an enterprise actively deploying AI internally). The conversation, hosted at AWS re:Invent, offers candid insights into the operational realities of deploying large language models and agentic AI systems in production environments.

The panelists include Marcel Pivotal from Glean (solutions architect with AWS and generative AI implementation experience), Rohit Bala Subramanyan from Deloitte (28-year technology veteran now leading AI and agentic AI services), and Ravia Mamou from DocuSign (Senior Director leading AI deployment and agent development across the company). This diversity of perspectives provides a balanced view of LLMOps from vendor, consultant, and practitioner angles.

## Enterprise AI Adoption and Production Realities

The discussion opens with perspectives on AI adoption rates, referencing a Gartner prediction that 33% of enterprise software applications will include agentic AI enabling 15% of enterprise decisions. The panelists offer nuanced views on this prediction. Rohit from Deloitte confirms AI is pervasive across industries including life sciences, financial services, banking, and insurance, but questions whether current adoption has reached the predicted levels. He emphasizes that while agentic AI is "here to stay and grow," certain industry sectors are leading while others lag behind.

From DocuSign's perspective, Ravia describes a clear organizational shift toward AI adoption. The company has adopted an "AI-first mindset strategy" where every team is encouraged to consider how AI can accelerate their work. However, he identifies a critical distinction regarding autonomous agents: while DocuSign is building agents for multiple business processes, true autonomous operation remains aspirational rather than current reality. He suggests that the shift from probabilistic to deterministic models will be necessary before organizations feel confident allowing fully autonomous agent operation.

## Autonomy, Trust, and Human-in-the-Loop

A significant portion of the discussion centers on the semantic and practical challenges around "autonomous" AI. Marcel from Glean clarifies that autonomy in AI can mean two things: agents taking action without human intervention, or agents that can think, plan, and evaluate independently while still requiring human approval. In his experience across multiple customers, he emphasizes that "human in the loop is critical" and that evaluation mechanisms must be in place not just during pilot phases but also in production deployments. He notes that few use cases are truly comfortable running without human oversight.

The panel discusses building trust incrementally. Marcel explains that as agent pipelines mature and organizations gain confidence through consistent performance, they may gradually move toward more autonomous operation. However, the current state across most enterprises involves careful monitoring and validation of agent outputs before allowing them to execute actions.

## Organizational Complexity as a Primary Bottleneck

All three panelists identify organizational complexity as a more significant challenge than technical complexity. Ravia shares DocuSign's early journey, describing how when GPT-3.5 was released, initially only a small team explored the technology. However, as multiple teams began experimenting independently, the company faced proliferation challenges: different teams selecting different tools for similar problems, confusion about when to use which models (Google Gemini, internal GPT implementations, enterprise search tools like Glean), and difficulties with training and enablement across the organization.

The rapid evolution of foundation models (from GPT-3.5 to GPT-4 to GPT-5.1, and various Gemini versions) creates additional complexity. While models evolve quickly, organizational processes around training, security approval, and legal review move more slowly, creating friction. Ravia notes that organizations must account for multiple approval layers and extensive training requirements to minimize this complexity.

Marcel reinforces that "technical complexity mirrors organizational complexity." As organizations grow, they implement tools that reflect their structure, resulting in data silos and governance problems. He emphasizes that security teams should be engaged "from day one" to navigate access challenges across these data silos and enable context sharing with AI systems.

Rohit from Deloitte observes that successful AI implementation, particularly agentic AI, isn't about "bolting an AI solution to a legacy scenario" but rather "reimagining workflows and processes." This reimagination inherently involves business stakeholders, data teams, technology teams, and virtually every part of an organization. After learning from early failures, Deloitte now emphasizes strategic approaches to roadmaps, business value capture defined upfront, clear success criteria, and comprehensive stakeholder engagement from the beginning.

## Data Integration and Technical Architecture

The panel addresses the challenge of connecting AI systems to enterprise data spread across multiple systems and silos. Marcel describes the evolution of integration approaches: traditional connectors that ingest and merge data, the recent emergence of Model Context Protocol (MCP) for API-based connections, and the need for wrapper APIs around legacy systems that lack modern interfaces. He stresses that better enterprise context leads to better AI responses, and that bridging data silos is key to success.

Rohit introduces an interesting tension: while agents deliver maximum value when operating across workflows in operational systems, many organizations are reluctant to provide direct access to these mission-critical systems. This has led to what he calls the "reimportance" of data lakes as interim architecture. Rather than allowing direct operational system access, some organizations extract data to lakes and run AI workloads against these copies. This represents a pragmatic middle ground between AI's need for comprehensive data and operational teams' concerns about system integrity.

The moderator offers an important psychological insight: teams protecting operational data have been trained for years to prioritize security, availability, and data quality. Their reluctance to share data may not stem from job security fears but from professional responsibility to protect critical company assets. Building trust requires demonstrating that AI teams understand and respect these concerns.

## Governance and Agent Development Patterns

DocuSign's experience reveals evolving governance challenges around agent creation and sharing. Ravia explains that the company is developing an "agent sharing governance strategy" because the critical question isn't who can create agents, but rather what agents can do and with whom they'll be shared. An agent serving 5-6 people as a digital assistant requires different governance than one serving 2,000-3,000 people at the department level, or 10,000+ people company-wide.

For high-stakes use cases like HR recruitment, performance evaluation, or hiring processes, governance becomes even more critical. Questions arise around hallucination prevention, bias mitigation, and whether managers can rely on agent outputs for decisions. This requires involvement not just from security teams but from legal, HR, and other stakeholders.

The panel explores who should build agents, with audience polling revealing many attendees have built agents themselves. Ravia observes that business users who were initially reluctant are now proactively approaching his team to build agents, particularly using low-code platforms. He emphasizes that skill development around prompting, context management, and understanding model intricacies will be crucial, and that business users are increasingly developing these capabilities.

Marcel advocates a three-step approach: enablement (teaching business users agent concepts, prompting best practices, and maintaining internal documentation libraries), guardrails (technical controls around data source access and permissions), and leveraging business user expertise (understanding how humans currently perform workflows before automating them).

The panel reaches consensus that successful agent development requires collaboration between business experts who understand workflows and IT experts who can harden, refine, and promote prototypes to production. Neither pure bottom-up (users create everything) nor pure top-down (IT creates everything) approaches succeed. Rohit envisions future organizational structures with AI Centers of Excellence that enable business-side development within governed frameworks using appropriate tooling and processes.

## Advanced LLMOps Capabilities

The discussion touches on several advanced LLMOps patterns emerging in production deployments:

**Meta-agents for agent discovery**: Glean internally runs an agent that analyzes user workflows and suggests which agents to build. This represents AI being used to identify AI opportunities, creating a feedback loop for continuous improvement.

**Prompt interrogation and refinement**: Marcel describes how modern foundation models now include preprocessing steps that evaluate prompt ambiguity, improve question quality, and identify user intent before generating responses. Some systems can even identify poorly written agents and suggest improvements or self-correct.

**Model agnosticism**: The moderator emphasizes that organizations should avoid over-indexing on specific LLM providers (OpenAI, Google, Anthropic) since the competitive landscape shifts rapidly. Audience polling confirmed no clear consensus on which provider has the "best" model, and everyone acknowledged they don't know who will lead in 18 months. This argues for open, multi-model ecosystems rather than vendor lock-in.

**Incremental value realization**: Referencing KPMG research, the panel discusses how AI value is achieved incrementally rather than through revolutionary transformation. This requires careful expectation management with leadership and realistic timelines.

## Value Measurement and ROI Challenges

Measuring AI value emerges as one of the most challenging aspects of LLMOps. Ravia candidly admits that despite being asked to build a dashboard showing tool value, he's "really, really struggling" because existing tools measure utilization (how many people use it, for how long) but not actual value delivered. Privacy concerns prevent teams from examining what users are doing with AI tools or what specific value they derive.

The moderator points out a fundamental challenge: organizations often can't measure baseline productivity without AI, making it difficult to assess AI's impact. Rohit reframes the question entirely, arguing that measuring "tooling value" isn't the right approach. Instead, since AI should re-engineer business processes, each use case should have robust KPIs defined upfront to measure business value uplift rather than tool utilization.

This leads to broader change management considerations. Deloitte embeds comprehensive change management into AI implementations, including value measurement, upskilling, target state operating model definition, communication strategies to address user concerns, and adoption tracking. Rohit describes "right brain and left brain" teams working together, with business teams handling change management and value capture alongside technology teams, all collaborating with organizational users.

Marcel adds that organizations need feedback loops from end users about agent helpfulness, areas for improvement, and hallucination issues. This user feedback becomes essential for measuring quality and driving iterative improvement in production deployments.

## Practical Recommendations for Production AI

In closing recommendations, the panelists offer distilled wisdom:

**Ravia (DocuSign)**: Take calculated risks to capture AI value, but ensure adequate guardrails are in place. Balance innovation with governance.

**Rohit (Deloitte)**: Focus relentlessly on business value. When AI is viewed through a business lens solving real business problems, it enables both use case success and meaningful value measurement.

**Marcel (Glean)**: Start small, establish governance early, understand your enterprise context deeply, don't over-index on which model to use, implement guardrails, and crucially, bring security teams in from day one rather than as an afterthought.

The discussion reveals that successful LLMOps in enterprise environments requires balancing multiple tensions: innovation versus governance, business-led versus IT-led development, autonomous capability versus human oversight, and rapid model evolution versus deliberate organizational change. The most successful deployments integrate these considerations from the start rather than treating them as separate phases or afterthoughts.