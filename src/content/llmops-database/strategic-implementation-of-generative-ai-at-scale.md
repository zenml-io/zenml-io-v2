---
title: "Strategic Implementation of Generative AI at Scale"
slug: "strategic-implementation-of-generative-ai-at-scale"
draft: false
webflow:
  siteId: "64a817a2e7e2208272d1ce30"
  itemId: "673f3faa9ea4287b56e69a1c"
  exportedAt: "2026-02-11T13:30:32.135Z"
  source: "live"
  lastPublished: "2025-12-23T12:21:17.478Z"
  lastUpdated: "2025-12-18T17:38:08.118Z"
  createdOn: "2024-11-21T14:11:54.739Z"
llmopsTags:
  - "chatbot"
  - "cicd"
  - "code-generation"
  - "compliance"
  - "devops"
  - "document-processing"
  - "documentation"
  - "guardrails"
  - "human-in-the-loop"
  - "knowledge-distillation"
  - "microsoft-azure"
  - "monitoring"
  - "openai"
  - "poc"
  - "prompt-engineering"
  - "regulatory-compliance"
  - "reliability"
  - "scalability"
  - "scaling"
  - "security"
  - "semantic-search"
industryTags: "automotive"
company: "TomTom"
summary: "TomTom implemented a comprehensive generative AI strategy across their organization, using a hub-and-spoke model to democratize AI innovation. They successfully deployed multiple AI applications including a ChatGPT location plugin, an in-car AI assistant (Tommy), and internal tools for mapmaking and development, all without significant additional investment. The strategy focused on responsible AI use, workforce upskilling, and strategic partnerships with cloud providers, resulting in 30-60% task performance improvements."
link: "https://engineering.tomtom.com/GenAI-journey/"
year: 2023
seo:
  title: "TomTom: Strategic Implementation of Generative AI at Scale - ZenML LLMOps Database"
  description: "TomTom implemented a comprehensive generative AI strategy across their organization, using a hub-and-spoke model to democratize AI innovation. They successfully deployed multiple AI applications including a ChatGPT location plugin, an in-car AI assistant (Tommy), and internal tools for mapmaking and development, all without significant additional investment. The strategy focused on responsible AI use, workforce upskilling, and strategic partnerships with cloud providers, resulting in 30-60% task performance improvements."
  canonical: "https://www.zenml.io/llmops-database/strategic-implementation-of-generative-ai-at-scale"
  ogTitle: "TomTom: Strategic Implementation of Generative AI at Scale - ZenML LLMOps Database"
  ogDescription: "TomTom implemented a comprehensive generative AI strategy across their organization, using a hub-and-spoke model to democratize AI innovation. They successfully deployed multiple AI applications including a ChatGPT location plugin, an in-car AI assistant (Tommy), and internal tools for mapmaking and development, all without significant additional investment. The strategy focused on responsible AI use, workforce upskilling, and strategic partnerships with cloud providers, resulting in 30-60% task performance improvements."
---

## Overview

TomTom, a global location technology company known for navigation systems and mapping data, embarked on a comprehensive Generative AI journey following ChatGPT's public release in December 2022. This case study, published in November 2023, details their strategic approach to adopting GenAI across both external products and internal operations. The company's approach is notable for its emphasis on democratizing innovation through organizational structure rather than purely technological solutions, making it a valuable reference for enterprises looking to scale GenAI adoption systematically.

The core challenge TomTom faced was twofold: adapting their location technology for AI-powered use cases externally while simultaneously streamlining internal operations with AI. Their stated goals included unlocking new revenue streams, maintaining market relevance, improving quality, and reducing costs. What makes this case study particularly interesting from an LLMOps perspective is how they structured their organization and processes to deliver multiple GenAI applications without substantial additional investment or significant hiring.

## Strategic Framework and Organizational Structure

TomTom adopted what they call a "hub-and-spoke" model to structure their GenAI innovation efforts. The Innovation Hub consists of a compact group of GenAI specialists who oversee strategic directions and boost GenAI proficiency across the organization. This central team is responsible for core AI applications and provides centralized coordination, infrastructure guidance, and operational support.

The "spokes" are local teams with domain knowledge and business understanding who identify opportunities for GenAI applications within their specific areas. The hub and spoke teams collaborate on "sponsored projects" where they jointly develop proof-of-concept solutions, typically involving 1-2 people over a few weeks. Once a product matures, the spoke team takes over full ownership and maintenance while the hub team provides consultative support.

This organizational approach to LLMOps is significant because it addresses a common challenge in enterprise AI adoption: how to scale innovation without requiring AI specialists embedded in every team. By centralizing expertise while distributing innovation authority, TomTom claims to have reduced development time from quarters (with traditional AI approaches) to mere weeks with GenAI.

## Production Applications and Use Cases

The case study mentions several GenAI applications that TomTom has deployed or is developing:

**Tommy - In-Car AI Assistant**: TomTom developed an AI assistant for in-car digital cockpits called Tommy. While specific technical details are not provided, this represents a production deployment in a safety-critical automotive environment, suggesting significant attention to reliability and latency requirements. The assistant was showcased at CES 2024.

**ChatGPT Location Plugin**: TomTom built what they describe as "the world's first location plugin for ChatGPT," allowing the ChatGPT platform to access TomTom's location technology. This represents an interesting LLMOps pattern of exposing enterprise capabilities to third-party LLM platforms rather than building entirely custom solutions.

**Developer Documentation Chatbot**: The company implemented a chat interface for their developer documentation, aimed at improving the developer experience for users of their APIs and SDKs. This is a common RAG (Retrieval-Augmented Generation) use case, though specific implementation details are not provided.

**Internal Workflow Applications**: Various internal applications were developed for tasks including analyzing search logs, classifying search intent, calibrating search confidence, creating live event services from social media data, AI-assisted code reviews, generating release notes, triaging tickets, and interacting with internal documents.

## Infrastructure and Tooling Decisions

TomTom's infrastructure strategy shows a clear preference for leveraging existing cloud provider capabilities over building custom foundational models. They explicitly partnered with Azure OpenAI for foundational models and infrastructure, which is a pragmatic LLMOps decision that reduces operational burden while providing enterprise-grade security and compliance features.

For internal tooling, TomTom deployed several AI-assisted development tools:

**GitHub Copilot**: Deployed for developer productivity enhancement. While the source mentions a follow-up blog about their Copilot experience, this case study doesn't provide detailed metrics on adoption or productivity gains.

**Chatty**: An open-source, internally hosted version of ChatGPT (available at https://github.com/rijnb/chatty-server/) deployed for enhanced data privacy. This represents an important LLMOps pattern of self-hosting chat interfaces while using external API backends to maintain control over data flows and standardize usage patterns.

**AI Code Review Tool**: While not detailed, this suggests integration of LLM capabilities into their development workflow for automated code quality checks.

**Microsoft 365 CoPilot**: Mentioned as beginning beta trials, indicating expansion of GenAI tools beyond engineering to broader business functions.

## Responsible AI and Governance

TomTom acknowledges key GenAI challenges including hallucinations (outputs that seem plausible but are factually incorrect) and potential confidentiality breaches. Their approach to responsible AI includes several LLMOps-relevant practices:

**Knowledge Grounding Techniques**: They incorporate knowledge grounding in product and process development, which typically involves RAG patterns to anchor LLM outputs in verified information sources. This is critical for location technology where accuracy is paramount.

**Internal ChatGPT Deployment**: The in-house ChatGPT deployment (Chatty) serves dual purposes: safeguarding sensitive data from external services and standardizing GenAI best practices across the organization. This is a common enterprise LLMOps pattern that provides centralized logging, monitoring, and policy enforcement.

**Training and Awareness**: Beyond technical guardrails, TomTom conducts training sessions to raise awareness about GenAI risks and prevent misuse. This human-in-the-loop approach acknowledges that technical controls alone are insufficient for responsible AI deployment.

**Azure ML Responsible AI Guidelines**: They mention using Azure ML's responsible AI guidelines for biannual audits and strategy reviews of GenAI initiatives, suggesting integration with Microsoft's broader responsible AI framework.

## Build vs. Buy Decisions

TomTom's strategy explicitly addresses the build vs. buy question for different application categories:

- **Non-core applications**: They prioritize purchasing over building, citing examples like AI tools in Office, Enterprise Search, Salesforce, and Workday.
- **Occasional uses (AIGC)**: They look to third-party solutions for artificial intelligence-generated content needs.
- **Core location technology applications**: They build custom applications but explicitly avoid building foundational models due to upfront cost and ROI concerns.

This pragmatic approach to resource allocation is a hallmark of mature LLMOps thinking, focusing engineering effort on areas of competitive differentiation while leveraging commoditized solutions elsewhere.

## Upskilling and Knowledge Management

A significant portion of TomTom's GenAI strategy focuses on workforce upskilling, which directly impacts LLMOps success:

**Weekly AI Newsletter**: Regular communication keeping teams informed about advancements and fostering knowledge sharing, which has reportedly catalyzed new GenAI projects.

**New Hire Onboarding**: Engineers and non-engineering staff receive GenAI tooling guides and best practices from day one, ensuring consistent usage patterns.

**GenAI Hackathons**: Two hackathons in 2023 resulted in winning solutions that moved to production, demonstrating a pathway from experimentation to deployment.

**Office Hours**: The Hub team provides consultations and project mentorship, facilitating collaborative ideation across teams.

**Evolving Knowledge Base**: Internal documentation promoting open knowledge sharing and pattern recognition across projects.

## Critical Assessment

While this case study provides valuable insights into organizational approaches to GenAI adoption, there are several areas where claims should be viewed with appropriate skepticism:

The claim of reducing development time from "quarters to weeks" is common in GenAI marketing but lacks specific metrics or before/after comparisons to validate. Similarly, the statement about achieving results "without significant increase in innovation budget" would benefit from actual figures.

The case study is relatively light on technical implementation details, production metrics, or specific challenges encountered during deployment. Topics like latency optimization, model selection criteria, testing and evaluation strategies, and monitoring approaches are not addressed.

The reference to early research indicating GenAI can improve task performance by 30-60% cites Andrew Ng's talk but should be taken as a general industry observation rather than TomTom-specific results.

Nevertheless, the organizational and governance frameworks described represent practical LLMOps patterns that enterprises can learn from, particularly the hub-and-spoke model for scaling innovation and the emphasis on responsible AI governance alongside deployment speed.