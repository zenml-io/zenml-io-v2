---
title: "Multimodal Search and Conversational AI for Fashion E-commerce Catalog"
slug: "multimodal-search-and-conversational-ai-for-fashion-e-commerce-catalog"
draft: false
webflow:
  siteId: "64a817a2e7e2208272d1ce30"
  itemId: "674f1f9a2caeacaf7604bc6f"
  exportedAt: "2026-02-11T13:30:32.135Z"
  source: "live"
  lastPublished: "2025-12-23T12:21:17.478Z"
  lastUpdated: "2025-12-18T16:47:15.401Z"
  createdOn: "2024-12-03T15:11:22.182Z"
llmopsTags:
  - "multi-modality"
  - "chatbot"
  - "question-answering"
  - "embeddings"
  - "semantic-search"
  - "vector-search"
  - "fastapi"
  - "openai"
industryTags: "e-commerce"
company: "Farfetch"
summary: "Farfetch developed a multimodal conversational search system called iFetch to enhance customer product discovery in their fashion marketplace. The system combines textual and visual search capabilities using advanced embedding models and CLIP-based multimodal representations, with specific adaptations for the fashion domain. They implemented semantic search strategies and extended CLIP with taxonomic information and label relaxation techniques to improve retrieval accuracy, particularly focusing on handling brand-specific queries and maintaining context in conversational interactions."
link: "https://medium.com/farfetch-tech-blog/multimodal-search-and-browsing-in-the-product-catalogue-a-primer-for-conversational-search-dd5246bb0d62"
year: 2023
seo:
  title: "Farfetch: Multimodal Search and Conversational AI for Fashion E-commerce Catalog - ZenML LLMOps Database"
  description: "Farfetch developed a multimodal conversational search system called iFetch to enhance customer product discovery in their fashion marketplace. The system combines textual and visual search capabilities using advanced embedding models and CLIP-based multimodal representations, with specific adaptations for the fashion domain. They implemented semantic search strategies and extended CLIP with taxonomic information and label relaxation techniques to improve retrieval accuracy, particularly focusing on handling brand-specific queries and maintaining context in conversational interactions."
  canonical: "https://www.zenml.io/llmops-database/multimodal-search-and-conversational-ai-for-fashion-e-commerce-catalog"
  ogTitle: "Farfetch: Multimodal Search and Conversational AI for Fashion E-commerce Catalog - ZenML LLMOps Database"
  ogDescription: "Farfetch developed a multimodal conversational search system called iFetch to enhance customer product discovery in their fashion marketplace. The system combines textual and visual search capabilities using advanced embedding models and CLIP-based multimodal representations, with specific adaptations for the fashion domain. They implemented semantic search strategies and extended CLIP with taxonomic information and label relaxation techniques to improve retrieval accuracy, particularly focusing on handling brand-specific queries and maintaining context in conversational interactions."
---

## Overview

This case study originates from Farfetch, a global luxury fashion e-commerce platform that connects consumers with boutiques and brands worldwide. Unfortunately, the original Medium article has been deleted by its author (returning a 410 Gone HTTP status), which significantly limits the technical details available for analysis. The title of the deleted article was "Multimodal Search and Browsing in the Product Catalogue: A Primer for Conversational Search," which provides some indication of the technical direction Farfetch was exploring.

## Context and Limitations

It is important to note upfront that this summary is based on extremely limited information. The source content has been removed, and only the URL and title remain accessible. As such, the following analysis represents an informed speculation based on standard industry practices for multimodal and conversational search implementations in e-commerce, combined with the hints provided by the article's title.

Farfetch operates in the luxury fashion space, where product discovery is particularly challenging due to the visual nature of fashion, the complexity of describing clothing and accessories in text, and the diverse ways consumers search for products. The company has a significant tech blog presence and has historically published technical content about their engineering practices, which suggests they have an active engineering culture focused on sharing knowledge about their production systems.

## Inferred Technical Approach

Based on the title mentioning "multimodal search," the system likely involved combining multiple input modalities for product search. In the context of e-commerce and LLMOps, this typically involves:

**Visual Search Components**: Fashion e-commerce platforms commonly implement visual search capabilities that allow users to upload images or take photos of items they like. This requires embedding models (such as CLIP or similar vision-language models) that can create unified representations of both images and text in the same vector space. The production deployment of such systems involves managing embedding generation at scale, maintaining vector databases for similarity search, and ensuring low-latency responses for a good user experience.

**Text-Based Search Enhancement**: Traditional keyword search is often augmented with semantic search capabilities powered by language models. This allows users to search using natural language descriptions ("flowy summer dress in earth tones") rather than exact product attribute matches. Implementing this in production requires careful consideration of how to combine semantic similarity with traditional search ranking signals.

**Conversational Interfaces**: The mention of "conversational search" in the title suggests exploration of chat-based or dialogue-driven product discovery. This represents a significant LLMOps challenge as it requires:

- Maintaining conversation context across multiple turns
- Understanding user intent and translating it into product catalog queries
- Generating natural language responses that help guide users through the product selection process
- Handling the inherent ambiguity in fashion terminology and personal preferences

## Production Considerations for Such Systems

While the specific implementation details from Farfetch are unavailable, deploying multimodal and conversational search systems in production typically involves several key LLMOps considerations:

**Embedding Infrastructure**: Production systems need to manage embedding generation for large product catalogs, often millions of items with multiple images each. This requires efficient batch processing pipelines, incremental updates as new products are added, and strategies for handling model updates without disrupting service.

**Vector Database Management**: Similarity search at scale requires specialized vector databases or approximate nearest neighbor (ANN) indices. Production deployments must consider index rebuild times, memory requirements, query latency targets, and strategies for A/B testing different embedding models or search configurations.

**Latency and Performance**: E-commerce search has strict latency requirements since users expect near-instantaneous results. This creates tension with the computational cost of large language models and vision models, often requiring optimization techniques such as model distillation, caching strategies, or tiered approaches where simpler models handle common queries.

**Evaluation and Quality Measurement**: Measuring the quality of multimodal and conversational search is challenging. Traditional information retrieval metrics (precision, recall, NDCG) may need to be supplemented with user engagement metrics, conversion rates, and qualitative assessment of conversation quality.

**Handling Fashion-Specific Challenges**: Fashion search has unique challenges including seasonal trends, highly subjective style preferences, the importance of fit and sizing, and the visual complexity of fashion items. Production systems need to account for these domain-specific factors.

## Assessment and Conclusions

Without access to the original content, it is impossible to assess the actual implementation, results, or lessons learned from Farfetch's work on multimodal and conversational search. The deletion of the article by its author could indicate various things: the content may have been outdated, the author may have left the company, there may have been concerns about revealing proprietary information, or it may simply have been part of a content reorganization.

The topic itself—combining multimodal search with conversational interfaces for product discovery—represents an active and important area of development in e-commerce LLMOps. Companies in the fashion and retail space are investing heavily in these capabilities as they represent a significant opportunity to improve user experience and conversion rates.

For practitioners interested in this space, the lack of publicly available case studies from major e-commerce platforms like Farfetch highlights a common challenge in the LLMOps community: while there is significant investment in production LLM systems, detailed technical case studies about real-world deployments remain relatively rare, making it difficult for the broader community to learn from industry experience.

This case study entry serves primarily as a placeholder indicating that Farfetch was working in this space, though the specific technical details and outcomes remain unknown due to the content deletion.