---
title: "Transforming Vanilla PyTorch Code into Production Ready ML Pipeline - Without Selling Your Soul"
slug: "transforming-vanilla-pytorch-code-into-production-ready-ml-pipeline-without-selling-your-soul"
draft: false
webflow:
  siteId: "64a817a2e7e2208272d1ce30"
  itemId: "65316f8df9b3dff475fa595b"
  exportedAt: "2026-02-11T10:23:34.071Z"
  source: "live"
  lastPublished: "2024-01-26T14:57:53.329Z"
  lastUpdated: "2024-01-26T14:57:53.329Z"
  createdOn: "2023-10-19T18:03:57.970Z"
author: "felix-altenberger"
category: "zenml"
tags:
  - "zenml"
  - "integrations"
  - "mlops"
  - "pipelines"
  - "pytorch"
  - "tooling"
  - "wandb"
date: "2022-10-27T00:00:00.000Z"
readingTime: 24 Mins Read
mainImage:
  url: "https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/a0ba3c78/65316efcf9b3dff475f9db48_thumbnail__1_.gif"
seo:
  title: "Transforming Vanilla PyTorch Code into Production Ready ML Pipeline - Without Selling Your Soul - ZenML Blog"
  description: "Transform quickstart PyTorch code as a ZenML pipeline and add experiment tracking and secrets manager component."
  canonical: "https://www.zenml.io/blog/transforming-vanilla-pytorch-code-into-production-ready-ml-pipeline-without-selling-your-soul"
  ogImage: "https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/2f1d63af/65316efcf9b3dff475f9db48_thumbnail__1_.gif"
  ogTitle: "Transforming Vanilla PyTorch Code into Production Ready ML Pipeline - Without Selling Your Soul - ZenML Blog"
  ogDescription: "Transform quickstart PyTorch code as a ZenML pipeline and add experiment tracking and secrets manager component."
---

**Last updated:** November 22, 2022.

## ğŸ”¥ Motivation

Itâ€™s 2022, anyone can train a machine learning (ML) model these days. Libraries like [PyTorch](https://pytorch.org/), [Tensorflow](https://www.tensorflow.org/), and [Scikit-learn](https://scikit-learn.org/stable/index.html) have lowered the entry barrier so much, you can get started in minutes.

Needless to say, there are tons of quickstart notebooks out there that will walk you through step-by-step. While there are values in quickstarts, especially in the early stages, the code you see in quickstarts often look very different and â€œunusable in productionâ€, some people might say.

Or, is it?

Is there a way we could transform quickstart code so that they are usable for production ML? Is that even possible?!

With ZenML, yes it is ğŸš€.

<figure>
  <img src="https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/64abd488/65316f5e1e6c29ac57ef8425_meme.jpeg" alt="poster" />
</figure>

In this post, we will show you how to turn vanilla PyTorch code into a production-ready ML pipeline that can be run on any cloud infrastructure while incorporating the best practices of MLOps. Next, weâ€™ll also show how you can easily manage access credentials and include components like experiment trackers into your pipeline.

By the end of the post, youâ€™ll learn how to -

<ul id=""><li id="">Transform a vanilla PyTorch code into ZenML pipelines.</li><li id="">Visualize the pipeline on an interactive dashboard.</li><li id="">Configure a Secrets Manager to securely store and retrieve API keys.</li><li id="">Use the <a href="https://wandb.ai/" id="">Weights &amp; Biases</a> (W&amp;B) Experiment Tracker to log results and share them.</li></ul>

For those who prefer video, we showcased this during a community session on October 26, 2022. Otherwise, letâ€™s dive in!

<figure id="" class="w-richtext-figure-type-video w-richtext-align-fullwidth" style="padding-bottom:56.25%" data-rt-type="video" data-rt-align="fullwidth" data-rt-max-width="" data-rt-max-height="56.25%" data-rt-dimensions="0:0" data-page-url=""><div id=""><iframe src="https://www.youtube-nocookie.com/embed/YLKueXpAT8o" frameborder="0" allowfullscreen=""></iframe></div></figure>

## â˜•ï¸ Installation

Letâ€™s begin by installing all the packages weâ€™ll need. Weâ€™d highly recommend that you install ZenML in a virtual environment of your choice. Read more [in our docs](https://docs.zenml.io/v/0.21.0/getting-started/installation).

Also note that if youâ€™re running this on an M1 Mac, we have a special guide [here](https://docs.zenml.io/v/0.21.0/getting-started/installation/m1-mac-installation) to set it up.

Now in your virtual environment, run:

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
pip install "zenml[server]==0.21.1" torchvision==0.14.0
</code></pre></div>

To verify if the installation was successful type:

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
zenml version
</code></pre></div>

â€

If you donâ€™t encounter any error messages, weâ€™re ready to start hacking!

Letâ€™s initialize a ZenML repository within your current directory with:

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
zenml init
</code></pre></div>



This creates a .zen hidden folder in your current directory that stores the ZenML configs and management tools.

ZenML comes with various integrations, letâ€™s install the ones we will be using in this post:

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
zenml integration install pytorch wandb tensorboard mlflow -y
</code></pre></div>



Wondering if you can use other tools instead? Check out more integrations [here](https://zenml.io/integrations). You can even [write you own](https://docs.zenml.io/v/0.21.0/misc/integrating)!

## âœ… Vanilla PyTorch Code

Now that weâ€™re done with the setups, letâ€™s take a look at the *â€œhello worldâ€* of PyTorch on the [quickstart page](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html).

The code look like the following.

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
import torch
from torch import nn
from torch.utils.data import DataLoader
from torchvision import datasets
from torchvision.transforms import ToTensor

# Download training data from open datasets.
training_data = datasets.FashionMNIST(
 &nbsp; &nbsp;root="data",
 &nbsp; &nbsp;train=True,
 &nbsp; &nbsp;download=True,
 &nbsp; &nbsp;transform=ToTensor(),
)

# Download test data from open datasets.
test_data = datasets.FashionMNIST(
 &nbsp; &nbsp;root="data",
 &nbsp; &nbsp;train=False,
 &nbsp; &nbsp;download=True,
 &nbsp; &nbsp;transform=ToTensor(),
)

batch_size = 64

# Create data loaders.
train_dataloader = DataLoader(training_data, batch_size=batch_size)
test_dataloader = DataLoader(test_data, batch_size=batch_size)

for X, y in test_dataloader:
 &nbsp; &nbsp;print(f"Shape of X [N, C, H, W]: {X.shape}")
 &nbsp; &nbsp;print(f"Shape of y: {y.shape} {y.dtype}")
 &nbsp; &nbsp;break

# Get cpu or gpu device for training.
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using {device} device")

# Define model
class NeuralNetwork(nn.Module):
 &nbsp; &nbsp;def __init__(self):
 &nbsp; &nbsp; &nbsp; &nbsp;super().__init__()
 &nbsp; &nbsp; &nbsp; &nbsp;self.flatten = nn.Flatten()
 &nbsp; &nbsp; &nbsp; &nbsp;self.linear_relu_stack = nn.Sequential(
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;nn.Linear(28*28, 512),
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;nn.ReLU(),
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;nn.Linear(512, 512),
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;nn.ReLU(),
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;nn.Linear(512, 10)
 &nbsp; &nbsp; &nbsp; &nbsp;)

 &nbsp; &nbsp;def forward(self, x):
 &nbsp; &nbsp; &nbsp; &nbsp;x = self.flatten(x)
 &nbsp; &nbsp; &nbsp; &nbsp;logits = self.linear_relu_stack(x)
 &nbsp; &nbsp; &nbsp; &nbsp;return logits

model = NeuralNetwork().to(device)
print(model)

loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)

def train(dataloader, model, loss_fn, optimizer):
 &nbsp; &nbsp;size = len(dataloader.dataset)
 &nbsp; &nbsp;model.train()
 &nbsp; &nbsp;for batch, (X, y) in enumerate(dataloader):
 &nbsp; &nbsp; &nbsp; &nbsp;X, y = X.to(device), y.to(device)

 &nbsp; &nbsp; &nbsp; &nbsp;# Compute prediction error
 &nbsp; &nbsp; &nbsp; &nbsp;pred = model(X)
 &nbsp; &nbsp; &nbsp; &nbsp;loss = loss_fn(pred, y)

 &nbsp; &nbsp; &nbsp; &nbsp;# Backpropagation
 &nbsp; &nbsp; &nbsp; &nbsp;optimizer.zero_grad()
 &nbsp; &nbsp; &nbsp; &nbsp;loss.backward()
 &nbsp; &nbsp; &nbsp; &nbsp;optimizer.step()

 &nbsp; &nbsp; &nbsp; &nbsp;if batch % 100 == 0:
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;loss, current = loss.item(), batch * len(X)
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;print(f"loss: {loss:&gt;7f} &nbsp;[{current:&gt;5d}/{size:&gt;5d}]")

def test(dataloader, model, loss_fn):
 &nbsp; &nbsp;size = len(dataloader.dataset)
 &nbsp; &nbsp;num_batches = len(dataloader)
 &nbsp; &nbsp;model.eval()
 &nbsp; &nbsp;test_loss, correct = 0, 0
 &nbsp; &nbsp;with torch.no_grad():
 &nbsp; &nbsp; &nbsp; &nbsp;for X, y in dataloader:
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;X, y = X.to(device), y.to(device)
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;pred = model(X)
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;test_loss += loss_fn(pred, y).item()
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;correct += (pred.argmax(1) == y).type(torch.float).sum().item()
 &nbsp; &nbsp;test_loss /= num_batches
 &nbsp; &nbsp;correct /= size
 &nbsp; &nbsp;print(f"Test Error: \n Accuracy: {(100*correct):&gt;0.1f}%, Avg loss: {test_loss:&gt;8f} \n")


epochs = 5
for t in range(epochs):
 &nbsp; &nbsp;print(f"Epoch {t+1}\n-------------------------------")
 &nbsp; &nbsp;train(train_dataloader, model, loss_fn, optimizer)
 &nbsp; &nbsp;test(test_dataloader, model, loss_fn)
print("Done!")

</code></pre></div>

â€

You can put all the code into a .py file, and it should run without a problem.

Now letâ€™s see how we can transform the code into a ZenML pipeline.

## ğŸ¥³ Transforming PyTorch code into a ZenML Pipeline.

Before we start, weâ€™d like to first tell you about the concept of *pipeline* and *step* in ZenML. This concept will come in handy later when we code.

In ZenML, a pipeline consists of a series of steps, organized in any order that makes sense for your use case.

The following illustration is a simple pipeline that consists of three steps running one after another.

<figure>
  <img src="https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/cd63a9e1/65316f5ef10545815b37aa46_pipeline_step.gif" alt="pipeline_steps" />
</figure>

The figure above is the exact pipeline and steps that we will construct from the vanilla PyTorch code. Letâ€™s start the transformation.

First, import modules from torch, torchvision and zenml.

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
import torch
from torch import nn
from torch.utils.data import DataLoader
from torchvision import datasets
from torchvision.transforms import ToTensor

from zenml.pipelines import pipeline
from zenml.steps import step, Output
</code></pre></div>

â€

Next, letâ€™s define the pipeline.

You can do this by putting a @pipeline decorator above the function definition.

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
@pipeline
def pytorch_experiment_tracking_pipeline(
 &nbsp; &nbsp;load_data,
 &nbsp; &nbsp;load_model,
 &nbsp; &nbsp;train_test,
):
 &nbsp; &nbsp;"""A `pipeline` to load data, load model, and train/evaluate the model."""
 &nbsp; &nbsp;train_dataloader, test_dataloader = load_data()
 &nbsp; &nbsp;model = load_model()
 &nbsp; &nbsp;train_test(model, train_dataloader, test_dataloader)
</code></pre></div>

â€

The pipeline we just wrote takes three steps as the input namely - load_data, load_model, and train_test. Each step runs sequentially one after another.

Next, letâ€™s define what the steps actually do. We can define a step in the same way we define a pipeline, except we put a @step decorator now.

Letâ€™s start with the first step to load the data.

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
@step
def load_data() -&gt; Output(
 &nbsp; &nbsp;train_dataloader=DataLoader, test_dataloader=DataLoader
):
 &nbsp; &nbsp;"""A `step` to load the Fashion MNIST dataset as a tuple of torch Datasets."""
 &nbsp; &nbsp;batch_size = 64

 &nbsp; &nbsp;# Download training data from open datasets.
 &nbsp; &nbsp;training_data = datasets.FashionMNIST(
 &nbsp; &nbsp; &nbsp; &nbsp;root="data",
 &nbsp; &nbsp; &nbsp; &nbsp;train=True,
 &nbsp; &nbsp; &nbsp; &nbsp;download=True,
 &nbsp; &nbsp; &nbsp; &nbsp;transform=ToTensor(),
 &nbsp; &nbsp;)

 &nbsp; &nbsp;# Download test data from open datasets.
 &nbsp; &nbsp;test_data = datasets.FashionMNIST(
 &nbsp; &nbsp; &nbsp; &nbsp;root="data",
 &nbsp; &nbsp; &nbsp; &nbsp;train=False,
 &nbsp; &nbsp; &nbsp; &nbsp;download=True,
 &nbsp; &nbsp; &nbsp; &nbsp;transform=ToTensor(),
 &nbsp; &nbsp;)

 &nbsp; &nbsp;# Create data loaders.
 &nbsp; &nbsp;train_dataloader = DataLoader(training_data, batch_size=batch_size)
 &nbsp; &nbsp;test_dataloader = DataLoader(test_data, batch_size=batch_size)

 &nbsp; &nbsp;return train_dataloader, test_dataloader
</code></pre></div>

â€

One of the best practices we keep when defining a step is [type annotation](https://blog.logrocket.com/understanding-type-annotation-python/). In simple terms, this means we define the data type for all the inputs and outputs of a step. This is a requirement when defining a step.

For the load_data step above, the outputs of the step are the train and test dataloaders of the DataLoader type in PyTorch. All you have to do is append Output(train_dataloader=DataLoader, test_dataloader=DataLoader) to the function name.

Now, letâ€™s use the same method and define our next step to load the model.

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
class NeuralNetwork(nn.Module):
 &nbsp; &nbsp;def __init__(self):
 &nbsp; &nbsp; &nbsp; &nbsp;super(NeuralNetwork, self).__init__()
 &nbsp; &nbsp; &nbsp; &nbsp;self.flatten = nn.Flatten()
 &nbsp; &nbsp; &nbsp; &nbsp;self.linear_relu_stack = nn.Sequential(
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;nn.Linear(28 * 28, 512),
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;nn.ReLU(),
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;nn.Linear(512, 512),
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;nn.ReLU(),
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;nn.Linear(512, 10),
 &nbsp; &nbsp; &nbsp; &nbsp;)

 &nbsp; &nbsp;def forward(self, x):
 &nbsp; &nbsp; &nbsp; &nbsp;x = self.flatten(x)
 &nbsp; &nbsp; &nbsp; &nbsp;logits = self.linear_relu_stack(x)
 &nbsp; &nbsp; &nbsp; &nbsp;return logits

@step
def load_model() -&gt; nn.Module:
 &nbsp; &nbsp;"""A `step` to define a PyTorch model."""
 &nbsp; &nbsp;model = NeuralNetwork()
 &nbsp; &nbsp;print(model)
 &nbsp; &nbsp;return model
</code></pre></div>



And the last step, to train and evaluate the model.

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
# Get cpu or gpu device for training.
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using {device} device")

def train(dataloader, model, loss_fn, optimizer):
 &nbsp; &nbsp;"""A function to train a model for one epoch."""
 &nbsp; &nbsp;size = len(dataloader.dataset)
 &nbsp; &nbsp;model.train()
 &nbsp; &nbsp;for batch, (X, y) in enumerate(dataloader):
 &nbsp; &nbsp; &nbsp; &nbsp;X, y = X.to(device), y.to(device)

 &nbsp; &nbsp; &nbsp; &nbsp;# Compute prediction error
 &nbsp; &nbsp; &nbsp; &nbsp;pred = model(X)
 &nbsp; &nbsp; &nbsp; &nbsp;loss = loss_fn(pred, y)

 &nbsp; &nbsp; &nbsp; &nbsp;# Backpropagation
 &nbsp; &nbsp; &nbsp; &nbsp;optimizer.zero_grad()
 &nbsp; &nbsp; &nbsp; &nbsp;loss.backward()
 &nbsp; &nbsp; &nbsp; &nbsp;optimizer.step()

 &nbsp; &nbsp; &nbsp; &nbsp;if batch % 100 == 0:
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;loss, current = loss.item(), batch * len(X)
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;print(f"loss: {loss:&gt;7f} &nbsp;[{current:&gt;5d}/{size:&gt;5d}]")

def test(dataloader, model, loss_fn):
 &nbsp; &nbsp;"""A function to test a model on the validation / test dataset."""
 &nbsp; &nbsp;size = len(dataloader.dataset)
 &nbsp; &nbsp;num_batches = len(dataloader)
 &nbsp; &nbsp;model.eval()
 &nbsp; &nbsp;test_loss, correct = 0, 0
 &nbsp; &nbsp;with torch.no_grad():
 &nbsp; &nbsp; &nbsp; &nbsp;for X, y in dataloader:
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;X, y = X.to(device), y.to(device)
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;pred = model(X)
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;test_loss += loss_fn(pred, y).item()
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;correct += (pred.argmax(1) == y).type(torch.float).sum().item()
 &nbsp; &nbsp;test_loss /= num_batches
 &nbsp; &nbsp;correct /= size
 &nbsp; &nbsp;test_accuracy = 100*correct
 &nbsp; &nbsp;print(f"Test Error: \n Accuracy: {(100*correct):&gt;0.1f}%, Avg loss: {test_loss:&gt;8f} \n")

 &nbsp; &nbsp;return test_accuracy

@step
def train_test(
 &nbsp; &nbsp;model: nn.Module,
 &nbsp; &nbsp;train_dataloader: DataLoader, 
 &nbsp; &nbsp;test_dataloader: DataLoader
) -&gt; Output(trained_model=nn.Module, test_acc=float):
 &nbsp; &nbsp;"""A `step` to train and evaluate a torch model on given dataloaders."""
 &nbsp; &nbsp;lr = 1e-3
 &nbsp; &nbsp;epochs = 5

 &nbsp; &nbsp;model = model.to(device)
 &nbsp; &nbsp;loss_fn = nn.CrossEntropyLoss()
 &nbsp; &nbsp;optimizer = torch.optim.SGD(model.parameters(), lr=lr)
 &nbsp; &nbsp;test_acc = 0
 &nbsp; &nbsp;for t in range(epochs):
 &nbsp; &nbsp; &nbsp; &nbsp;print(f"Epoch {t+1}\n-------------------------------")
 &nbsp; &nbsp; &nbsp; &nbsp;train(train_dataloader, model, loss_fn, optimizer)
 &nbsp; &nbsp; &nbsp; &nbsp;test_acc = test(test_dataloader, model, loss_fn)
 &nbsp; &nbsp;print("Done!")

 &nbsp; &nbsp;return model, test_acc
</code></pre></div>



We are now done with defining all the steps that take place in a pipeline! Whatâ€™s left now is to run the pipeline by:

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
pytorch_experiment_tracking_pipeline(
 &nbsp; &nbsp;load_data=load_data(),
 &nbsp; &nbsp;load_model=load_model(),
 &nbsp; &nbsp;train_test=train_test(),
).run(unlisted=True)
</code></pre></div>

â€

And thatâ€™s it! How easy was that? We were only reorganizing the PyTorch code into a series of steps and a pipeline with ZenML. If you put all the code above in a .py script, it should run just like the vanilla PyTorch code in the quickstart.

So why does this matter?

First, youâ€™ve just transformed vanilla PyTorch code into a form that can be run on your local machine and any cloud infrastructure in production. Second, structuring your code into steps and pipelines makes the code modular and easily maintainable. Third, using ZenML pipelines earlier on in your project also means that the code you use in development will look similar to the code in production. This saves a huge refactoring cost when transitioning from development to production.

You can read more about other benefits of structuring your code with ZenML pipelines from the get-go [here](https://blog.zenml.io/ml-pipelines-from-the-start/). Learn more about other ZenML features [here](https://zenml.io/features) which will save you a lot of time and resources in productionalizing ML models.

## ğŸ“Š ZenML Dashboard

ZenML comes with a handy [dashboard](https://github.com/zenml-io/zenml-dashboard) that lets you visualize the pipeline you just run. To open the dashboard, type in your terminal:

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
zenml up
</code></pre></div>

â€

This spins up a local [ZenML Server](https://docs.zenml.io/v/0.21.0/getting-started/core-concepts#zenml-server-and-dashboard) and launches the dashboard in the browser at http://127.0.0.1:8237). Key in default as the username and leave the password empty, then click â€œLog inâ€.

<figure>
  <img src="https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/f9f38201/65316f5e290e62113d94e87c_dashboard.gif" alt="login" />
</figure>

In the dashboard, youâ€™ll see all details about your *Steps*, *Pipelines*, *Runs*, *Stacks*, and *Stack Components*. Thereâ€™s also a neat visualization on the pipeline which lets you visually inspect your workflow.

The ZenML dashboard lets you visually inspect if the pipeline and steps are in order especially if your steps are complicated and many.

So far weâ€™ve only seen the details about the steps and pipelines in the dashboard. What about the experiment details like training accuracy, loss, etc?

In ZenML experiment details are logged using [Experiment Trackers](https://docs.zenml.io/v/0.21.0/component-gallery/experiment-trackers) - a component in ZenML.

In the next section, we will show how you can add Experiment Trackers into your workflow so you can monitor and share your experiment results.

## âš– Tracking Experiments and Keeping Secrets

Since we will be using W&B in our pipeline, make sure to create an account at the official [site](https://wandb.ai/home). Itâ€™s free to get started. Next, create a project and get the entity, project name and the API key.

Now with those details, letâ€™s put them in our code and start running them, shall we?

Of course not.

Sharing access credentials in your code or files is a quick way to set your butt on fire. We wouldnâ€™t recommend it.

<figure>
  <img src="https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/c5da66f6/65316f5f1dc62f53d46eaa75_fire.gif" alt="fire" />
</figure>

[via GIPHY](https://giphy.com/gifs/season-13-the-simpsons-13x20-xT5LMpPoihn5AsoNB6)

ZenML handles secret information like access credentials with a component known as [Secret Managers](https://docs.zenml.io/v/0.21.0/component-gallery/secrets-managers). Secrets Managers provide a secure way of storing and retrieving confidential information that is needed to run your ML pipelines.

Now letâ€™s configure our W&B credentials into the Secret Manager by running several commands in your terminal.

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
# Register secret manager
zenml secrets-manager register local --flavor=local

# Updating active stack with the secret manager
zenml stack update default -x local

# Registering the API key in the secret manager
zenml secrets-manager secret register wandb_secret --api_key=YOUR_W&amp;B_API_KEY
</code></pre></div>

â€

The commands above register a secret manager on your local machine, add them to your stack and registers the W&B API key as a secret.

Next, we will set up the experiment tracker by running:

â€

Remember to replace the entity and project_name argument with your own.

To view the configurations of the experiment tracker, run:

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
zenml experiment-tracker describe
</code></pre></div>

â€

which outputs:

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
Using the default local database.
Running with active project: 'default' (global)
Running with active stack: 'wandb_stack' (global)
Experiment_Tracker 'wandb_tracker' of flavor 'wandb' with id '47d74df8-b7bf-4e31-904d-cf8d7716d1a5' is owned by user 'default' and is 'private'.
 &nbsp;'wandb_tracker' EXPERIMENT_TRACKER Component &nbsp; 
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Configuration (ACTIVE) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”¯â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ COMPONENT_PROPERTY â”‚ VALUE &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;â”ƒ
â” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¨
â”ƒ API_KEY &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;â”‚ {{wandb_secret.api_key}} â”ƒ
â” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¨
â”ƒ ENTITY &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; â”‚ dnth &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; â”ƒ
â” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¨
â”ƒ PROJECT_NAME &nbsp; &nbsp; &nbsp; â”‚ zenml-pytorch-wandb &nbsp; &nbsp; &nbsp;â”ƒ
â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”·â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›
</code></pre></div>

â€

To get an overview of your current stack, run:

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
zenml stack describe
</code></pre></div>

which outputs:

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
Using the default local database.
Running with active project: 'default' (global)
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Stack Configuration &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”¯â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ COMPONENT_TYPE &nbsp; &nbsp; â”‚ COMPONENT_NAME â”ƒ
â” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¨
â”ƒ ORCHESTRATOR &nbsp; &nbsp; &nbsp; â”‚ default &nbsp; &nbsp; &nbsp; &nbsp;â”ƒ
â” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¨
â”ƒ SECRETS_MANAGER &nbsp; &nbsp;â”‚ local &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;â”ƒ
â” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¨
â”ƒ EXPERIMENT_TRACKER â”‚ wandb_tracker &nbsp;â”ƒ
â” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¨
â”ƒ ARTIFACT_STORE &nbsp; &nbsp; â”‚ default &nbsp; &nbsp; &nbsp; &nbsp;â”ƒ
â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”·â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›
</code></pre></div>

â€

With that, we are done configuring the Secrets Manager and Experiment Tracker securely.

Letâ€™s build on the code we used in the previous section. All we have to do is add a few more lines where we want W&B to log the information.

The first change is in the imports which include the wandb package now:

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
import torch
from torch import nn
from torch.utils.data import DataLoader
from torchvision import datasets
from torchvision.transforms import ToTensor

from zenml.pipelines import pipeline
from zenml.steps import step, Output

# ğŸ”¥ Import wandb package
import wandb
</code></pre></div>

â€

Next, we add a few lines in the train function. Specifically, we added global_step as the argument so that it can be used to track the loss value.

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
def train(dataloader, model, loss_fn, optimizer, global_step): 
 &nbsp; &nbsp;"""A function to train a model for one epoch."""
 &nbsp; &nbsp;size = len(dataloader.dataset)
 &nbsp; &nbsp;model.train()
 &nbsp; &nbsp;for batch, (X, y) in enumerate(dataloader):
 &nbsp; &nbsp; &nbsp; &nbsp;X, y = X.to(device), y.to(device)

 &nbsp; &nbsp; &nbsp; &nbsp;# Compute prediction error
 &nbsp; &nbsp; &nbsp; &nbsp;pred = model(X)
 &nbsp; &nbsp; &nbsp; &nbsp;loss = loss_fn(pred, y)

 &nbsp; &nbsp; &nbsp; &nbsp;# Backpropagation
 &nbsp; &nbsp; &nbsp; &nbsp;optimizer.zero_grad()
 &nbsp; &nbsp; &nbsp; &nbsp;loss.backward()
 &nbsp; &nbsp; &nbsp; &nbsp;optimizer.step()

 &nbsp; &nbsp; &nbsp; &nbsp;if batch % 100 == 0:
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;loss, current = loss.item(), batch * len(X)
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;print(f"loss: {loss:&gt;7f} &nbsp;[{current:&gt;5d}/{size:&gt;5d}]")

 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# ğŸ”¥ W&amp;B tracking
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;wandb.log({"Train Loss": loss}, step=global_step)
</code></pre></div>

â€

The same addition in the test function:

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
def test(dataloader, model, loss_fn, global_step):
 &nbsp; &nbsp;"""A function to test a model on the validation / test dataset."""
 &nbsp; &nbsp;size = len(dataloader.dataset)
 &nbsp; &nbsp;num_batches = len(dataloader)
 &nbsp; &nbsp;model.eval()
 &nbsp; &nbsp;test_loss, correct = 0, 0
 &nbsp; &nbsp;with torch.no_grad():
 &nbsp; &nbsp; &nbsp; &nbsp;for X, y in dataloader:
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;X, y = X.to(device), y.to(device)
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;pred = model(X)
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;test_loss += loss_fn(pred, y).item()
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;correct += (pred.argmax(1) == y).type(torch.float).sum().item()
 &nbsp; &nbsp;test_loss /= num_batches
 &nbsp; &nbsp;correct /= size
 &nbsp; &nbsp;test_accuracy = 100*correct
 &nbsp; &nbsp;print(f"Test Error: \n Accuracy: {(test_accuracy):&gt;0.1f}%, Avg loss: {test_loss:&gt;8f} \n")

 &nbsp; &nbsp;# ğŸ”¥ W&amp;B tracking
 &nbsp; &nbsp;wandb.log({"Test Loss": test_loss, "Test Accuracy": test_accuracy}, step=global_step)
</code></pre></div>



And finally some arguments to the step decorator:

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
@step(enable_cache=False, experiment_tracker="wandb_tracker")
def train_test(
 &nbsp; &nbsp;model: nn.Module,
 &nbsp; &nbsp;train_dataloader: DataLoader, 
 &nbsp; &nbsp;test_dataloader: DataLoader
) -&gt; Output(trained_model=nn.Module, test_acc=float):
 &nbsp; &nbsp;"""A step to train and evaluate a torch model on given dataloaders."""
 &nbsp; &nbsp;lr = 1e-3
 &nbsp; &nbsp;epochs = 5

 &nbsp; &nbsp;model = model.to(device)
 &nbsp; &nbsp;loss_fn = nn.CrossEntropyLoss()
 &nbsp; &nbsp;optimizer = torch.optim.SGD(model.parameters(), lr=lr)
 &nbsp; &nbsp;test_acc = 0
 &nbsp; &nbsp;for t in range(epochs):
 &nbsp; &nbsp; &nbsp; &nbsp;print(f"Epoch {t+1}\n-------------------------------")
 &nbsp; &nbsp; &nbsp; &nbsp;global_step = t * len(train_dataloader)
 &nbsp; &nbsp; &nbsp; &nbsp;train(train_dataloader, model, loss_fn, optimizer, global_step)
 &nbsp; &nbsp; &nbsp; &nbsp;test_acc = test(test_dataloader, model, loss_fn, global_step)
 &nbsp; &nbsp;print("Done!")

 &nbsp; &nbsp;return model, test_acc
</code></pre></div>

â€

The rest of the code remains the same. If you run the code the experiment metrics now should appear in your W&B dashboard. Hereâ€™s mine

<figure>
  <img src="https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/5a633282/65316f5ed77259beb157eb7f_wandb_dashboard.png" alt="dashboard" />
</figure>

In our example above, we did not log a lot of experiment information for simplicity. But you can always log other metrics from any steps in the pipeline with wandb.log.

## ğŸ’¡ Conclusion

Congratulations! You made it!! Thatâ€™s how easy it is to get started with ZenML.

In summary, youâ€™ve learned how to -

<ul id=""><li id="">Transform a vanilla PyTorch code into ZenML pipelines.</li><li id="">Visualize the pipeline on an interactive dashboard.</li><li id="">Configure a Secrets Manager to securely store and retrieve API keys.</li><li id="">Use the <a href="https://wandb.ai/" id="">Weights &amp; Biases</a> (W&amp;B) Experiment Tracker to log results and share them.</li></ul>

With this new superpower, you can turn any PyTorch code into ZenML steps and pipelines and accelerate your journey to production ML. Using the same steps you can also transform the code from other frameworks like Tensorflow/Keras. Check out this [example](https://github.com/zenml-io/zenml/tree/849d323139f3f4e3a8a2ca84a97fe225f9dfe7ce/examples/wandb_tracking).

<figure>
  <img src="https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/d14d252f/65316f5ef10545815b37aa42_success.gif" alt="success" />
</figure>

Where to go next? If youâ€™re starting with ZenML we recommend checking out the [quickstart](https://github.com/zenml-io/zenml/tree/main/examples/quickstart) to learn more. Or if youâ€™re new to MLOps, check out our [ZenBytes](https://github.com/zenml-io/zenbytes) repository where we walk you through short practical lessons using ZenML.

Got questions? [Join our Slack channel](https://zenml.io/slack-invite) and get a quick response from us!

â€**Last updated:** November 22, 2022.