---
title: "Deep Learning on 33,000,000 data points using a few lines of YAML"
slug: "deep-learning-on-33-000-000-data-points-using-a-few-lines-of-yaml"
draft: true
webflow:
  siteId: "64a817a2e7e2208272d1ce30"
  itemId: "652f550be3277fa772d42d74"
  exportedAt: "2026-02-11T10:23:34.071Z"
  source: "staged-only"
  lastUpdated: "2024-01-26T10:35:48.011Z"
  createdOn: "2023-10-18T03:46:19.987Z"
author: "hamza-tahir"
category: "zenml-updates"
tags:
  - "applied-zenml"
  - "pipelines"
  - "machine-learning"
  - "zenml"
date: "2020-05-04T00:00:00.000Z"
readingTime: 11 Mins Read
mainImage:
  url: "https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/206c6f6c/652f5478a3e04647d82c66a6_download__28_.png"
---

**Last updated:** November 3, 2022.

Over the last few years at [zenml](https://github.com/zenml.io), we have regularly dealt with datasets that contain millions of data points. Today, I want to write about how we use our machine learning platform, [ZenML](https://zenml.io/), to build production-ready distributed training pipelines. These pipelines are capable of dealing with millions of datapoints in a matter of hours. If you also want to build large-scale deep learning pipelines, sign up for [ZenML for free here](https://zenml.io/signup/) and follow along.

## Datasource

A good way to get a hold of a dataset of the size we want is [public Google BigQuery tables](https://cloud.google.com/bigquery/public-data). The one I chose for today's example is the [New York Citi Bike dataset](https://console.cloud.google.com/marketplace/details/city-of-new-york/nyc-citi-bike), which contains 33 million data points, holding information about various bike sharing trips in New York City. Here is a snippet of what the datasource looks like (*only relevant columns shown):

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
 &nbsp; birth_year | gender &nbsp; | &nbsp; end_station_id | &nbsp; start_station_id | &nbsp; tripduration | usertype
--------------+----------+------------------+--------------------+----------------+------------
 &nbsp; &nbsp; &nbsp; &nbsp; 1977 | Female &nbsp; | &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;103 | &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;100 | &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1012 | Subscriber
 &nbsp; &nbsp; &nbsp; &nbsp; 1991 | Male &nbsp; &nbsp; | &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1089 | &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 23 | &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;530 | Customer
... etc. etc. 33 million more times
</code></pre></div>



Our mission (if we choose to accept it) is to see if we can infer the birth_year of the person, given all the rest of the data in this table.

Sound interesting? Alright, let's begin.

## Building the Pipeline

When dealing with a dataset this large, its difficult to do some Pandas magic in a Jupyter notebook to wrangle with our data - I won't subject my poor ThinkPad to that punishment. That's why we created [ZenML](https://zenml.io/signup/) to deal with this problem ([amongst others](https://github.com/zenml-io/blog.zenml.io/blob/main/_posts/2020-03-01-deep_learning_in_production_is_broken.md)). For this post, I will assume you have the cengine CLI [installed](https://docs.zenml.io/) and ready to go.

As a summary, the cengine CLI will create, register and execute training pipelines, which will be managed by us on our cloud platform. One can create the pipeline declaratively by specifying a YAML configuration file.

For this example, I created a **simple feedforward neural network** pipeline. Here's how I did it:

### Step 0: Add the datasource

First thing to do is create a data source. As the BigQuery table is public, it can be added by running:

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
cengine datasource create bq --name citibike_trips \
 &nbsp;--project "bigquery-public-data" \
 &nbsp;--dataset new_york \
 &nbsp;--table citibike_trips \
 &nbsp;--table_type public
</code></pre></div>

‍

After that you can run

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
cengine datasource list
</code></pre></div>



And see the following details:‍

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
 Selection &nbsp; | &nbsp; ID | Name &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; | &nbsp; &nbsp; Rows | &nbsp; Cols | &nbsp; Size (MB)
-------------+------+--------------------+----------+--------+-------------
 * &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; | &nbsp; 16 | citibike_trips &nbsp; &nbsp; | 33319019 | &nbsp; &nbsp; 15 | &nbsp; &nbsp; &nbsp; &nbsp;4689

</code></pre></div>

‍

The data contains 33,319,019 rows with 15 columns.

### Step 1: Configure YAML - Features

Now we can build our YAML config. Usually I would use an easy-to-follow configure command to create this, but for this post it's easier to go section by section and build it manually. So open up a text editor (I'm a [Sublime Text](https://www.sublimetext.com/) guy but do it in [VIM](https://www.vim.org/) if you wish, whatever floats your boat):

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
features:
 &nbsp;end_station_id: {}
 &nbsp;gender: {}
 &nbsp;start_station_id: {}
 &nbsp;tripduration: {}
 &nbsp;usertype: {}
</code></pre></div>

‍

This will define the features we want to use for our pipeline. I dropped some features that I thought were redundant or could bias the model (like Bike ID). I mean, the model should have a challenge, right?

Also note that I didn't to any fancy embedding of start and end stations. As Andrew Ng says: *"Don’t start off trying to design and build the perfect system. Instead, build and train a basic system quickly"*. So lets get to a baseline first.

### Step 2: Configure YAML - Label

Ok next part is the label. That's also easy:

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
labels:
 &nbsp;birth_year:
 &nbsp; &nbsp;loss: mse
 &nbsp; &nbsp;metrics: [mae]
</code></pre></div>

So we define birth_year as the label, and say we want a mse (mean_squared_error) loss on the model. The metric I'll be tracking are mae (mean absolute error).

### Step 3: Configure YAML - Split

So we need to split our data for this to make any sense. ZenML let's you split up the data in a variety of ways into train and eval (more splits support on its way!). Lets write:

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
split:
 &nbsp;categorize_by: start_station_name
 &nbsp;index_ratio: { train: 0.9, eval: 0.1 }
</code></pre></div>

Three lines of YAML, but they pack a punch. ZenML will let you categorize your data before splitting it. For our case, we want all start stations to be equally represented to avoid any biases. So we grouped by the start_station_name and divided each possible group in a 90-10 split. For you SQL folk, this is similar to doing a GROUP BY and then taking a partition over an index. This way our training and test data will have data with all the stations.

I feel like splitting up data is a very under-appreciated part of machine learning and plays an important part in ML fairness, so I tried to make an appropriate split here.

### Step 4: Configure YAML - Trainer (Model definition)

We have arrived at, undoubtedly, the most interesting part of our YAML. The trainer, i.e., the actual model definition.

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
trainer:
 &nbsp;layers:
 &nbsp; &nbsp;- { type: dense, units: 64 } # a dense layer 64 units
 &nbsp; &nbsp;- { type: dense, units: 32 } # a dense layer with 32 units
 &nbsp;architecture: feedforward # can be feedforward or sequential
 &nbsp;last_activation: linear # last layer: we can take relu, but linear should also be fine
 &nbsp;num_output_units: 1 # How many units in the last layer? We choose 1 because we want to regress one number (i.e. date_of_birth)
 &nbsp;optimizer: adam # optimizer for loss function
 &nbsp;save_checkpoints_steps: 15000 # how many steps before we do a checkpoint evaluation for our Tensorboard logs
 &nbsp;eval_batch_size: 256 # batch size for evalulation that happens at every checkpoint
 &nbsp;train_batch_size: 256 # batch size for training
 &nbsp;train_steps: 230000 # two epochs
 &nbsp;type: regression # choose from [regression, classification, autoencoder]
</code></pre></div>

It's quite straightforward really - we define 2 dense layers, set the optimizer and a few more nuts and bolts. The whole trainer follows quite closely the [Keras](https://www.tensorflow.org/guide/keras) API, so it would be quite straightforward for most people. The interesting bit about this trainer is the train_steps and batch_size. One step is one whole batch passing through the network, so with a **33 million datapoint dataset**, **230,000** steps of **256** would be roughly **2** epochs of the data. Trust me, I did the math.

At this point you might be wondering what are the types of models you can create with this trainer key - so go ahead and read the developer [docs](https://docs.zenml.io/) for it. This part we're really trying to nail down and support for different sorts of models are always a priority.

### Step 5: Configure YAML - Evaluation (Splitting Metrics)

Almost there! One last thing we might want to do is to add some evaluator slices. What does that mean? Well it means that we may not just want to look at the overall metrics (i.e. overall mae) of the model, but the mae across a categorical column.

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
evaluator:
 &nbsp;birth_year: {} # I'd like to see how I did across each year
 &nbsp;gender: {} # I'd like to see if the model biases because of gender
 &nbsp;start_station_name: {} # I'd like to see how I did across each station
</code></pre></div>

I defined three such columns which I was interested in seeing sliced metrics across. You'll see how this plays into the evaluation part of our pipeline in a bit.

### The full config YAML

There are some things that I have intentionally skipped in the config for the sake of brevity. For reference, you can find the pipeline configuration ready to download [here]({{ site.url }}/assets/posts/train_30_mil_few_lines_yaml/citibike.yaml). I tried to annotate it with comments for clearer explanation. For further clarity, there is also always the [docs](https://docs.zenml.io/) to refer to. Most notably, the default key is perhaps important to look at as it defines the pre-processing steps that we took to normalize the data.

## Run the pipeline

Ok now I can register a pipeline called nyc_citibike_experiment like so:

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
cengine pipeline push my_config.yaml nyc_citibike_experiment
</code></pre></div>

ZenML will check your active datasource, and give an ops configuration that it deems suitable for the size of the job you're about to run. For this experiments, ZenML registered the pipeline with 4 workers at 96 cpus_per_worker. You can always change this if you want, but I decided to go for this configuration and ran the pipeline:

Enter Y for the safety prompt that appears, and let it run!

You should see a success message with your chosen configuration. The platform will provision these resources in the cloud, connect automatically to the datasource, and create a machine learning pipeline to train the model. All preprocessing steps of the pipeline will be distributed across the workers and cpus. The training will happen on a [Tesla K80](https://www.nvidia.com/en-gb/data-center/tesla-k80/) (distributed training coming soon!).

So now, you can sit back and relax. You don't need to watch dying Jupyter kernels or stare at as the steps go by on your terminal. Just grab a coffee, browse reddit, and chill.

## Evaluate the results

While running, the status of a pipeline can be checked with:

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
cengine pipeline status --pipeline_id <pipeline_id>
</pipeline_id></code></pre></div>

Sample output:

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
 &nbsp; ID | Name &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;| Pipeline Status &nbsp; | Completion &nbsp; | &nbsp; Compute Cost (€) | &nbsp; Training Cost (€) | &nbsp; Total Cost (€) | Execution Time
------+-----------------------------------+-------------------+--------------+--------------------+---------------------+------------------+------------------
 &nbsp; 1 &nbsp;| nyc_citibike_experiment &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; | Running &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; | 13% &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;| &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;0 | &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0 | &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;0 | 0:14:21.187081
</code></pre></div>

‍

Once the pipeline hits the 100% completion mark, I can see the compute (preprocessing + evaluation) cost and training cost it incurred. For me, this pipeline took **74 minutes**.

Preprocessing and training 33 million datapoints in just over an hour. Not too bad.

At that point, I can also evaluate it:

<div data-rt-embed-type="true"><pre><code class="language-bash" fs-codehighlight-element="code">
cengine pipeline evaluate <pipeline_id>
</pipeline_id></code></pre></div>

This opens up a pre-configured Jupyter notebook where I can view [Tensorboard](https://www.tensorflow.org/tensorboard) logs, along with the excellent [Tensorflow Model Analysis (TFMA)](https://github.com/tensorflow/model-analysis) plugin. Both of these will show me different things about the pipeline.

Tensorboard will show tensorboard things: The model graph, the train and eval loss etc. Here's how mine looks like:

![tensorboardlogs]({{ site.url }}/assets/posts/train_30_mil_few_lines_yaml/tensorboard_log.png)

That is pretty cool - Maybe we overtrained it at the 180,000th step as it took a jump in the loss, but the mae seems to keep decreasing. We're close to 9.6 mae overall, which isn't bad at all for this baseline model.

How about a deeper dive into the metrics? That's where TFMA comes into play. TFMA will show the metrics defined in the YAML and add the ability to slice the metric across the columns defined in the evaluator key. E.g. Lets slice it across birth_year to see how well it did for each year.

![tfma_logs]({{ site.url }}/assets/posts/train_30_mil_few_lines_yaml/tfma_1.png)

*Note: If you want to replicate this step just add birth_year in the generated notebook code where its specified.*

A deeper dive reveals that the model actually guessed the year of people born in 1977 pretty well (That's tested on ~11000 samples from that year). So its definitely learning something. We can now dive which years it did worse, and also other slices and see if we can gain anything from that when we iterate on our model.

## Wrap up

Now that we have the baseline model, its very simple to iterate on different sorts of models very quickly. The cool thing is that ZenML has stored all [intermediate states of the pipeline](https://docs.zenml.io/) (i.e. the preprocessed data) in an efficient and compressed binary format. Subsequent pipeline runs will **warmstart** the pipeline straight to the training part, given that everything else stays the same. This caching mechanism is actually quite powerful at this stage and can save up to 80% on time and cost. But I would leave that for a separate post, where we can take the same pipeline and iterate on quickly to arrive at a more accurate model! So stay tuned for that.

If you liked this post, please make sure to follow us on [Twitter](https://twitter.com/zenml_io), [LinkedIn](https://www.linkedin.com/company/zenml/) or just chat with us on our [Discord](https://discord.gg/HPBUKru) server.

We're actively looking for beta testers to test the platform and we have a whole bunch of features coming up, including distributed training, automatic model serving, hyper-parameter tuning and image support.Please visit the [docs](https://docs.zenml.io/) for details about the platform, and if interested [contact us](mailto:support@zenml.io) directly!

In the meantime, stay safe and hope to see you all soon!

‍