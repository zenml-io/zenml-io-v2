---
title: "Deepchecks"
slug: "deepchecks"
draft: false
webflow:
  siteId: "64a817a2e7e2208272d1ce30"
  itemId: "6527b8ac7a8eb1c405640636"
  exportedAt: "2026-02-11T10:23:34.071Z"
  source: "live"
  lastPublished: "2024-10-07T06:36:19.612Z"
  lastUpdated: "2024-10-07T06:36:19.612Z"
  createdOn: "2023-10-12T09:13:16.443Z"
integrationType: "data-validator"
logo:
  url: "https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/544fdc24/66d867e77279ed98da4c637f_deepchecks.png"
shortDescription: "Automate robust data and model validation in your ML pipelines with Deepchecks and ZenML"
docsUrl: "https://docs.zenml.io/stack-components/data-validators/deepchecks"
githubUrl: "https://github.com/zenml-io/zenml/tree/main/examples/deepchecks"
mainImage:
  url: "https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/19463ec9/66e0303fc6916694d6ca6c99_image__4_.png"
seo:
  title: "Integrate Deepchecks with ZenML - Data Validator Integrations"
  description: "Automate robust data and model validation in your ML pipelines with Deepchecks and ZenML"
  canonical: "https://www.zenml.io/integrations/deepchecks"
  ogImage: "https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/19463ec9/66e0303fc6916694d6ca6c99_image__4_.png"
  ogTitle: "Integrate Deepchecks with ZenML - Data Validator Integrations"
  ogDescription: "Automate robust data and model validation in your ML pipelines with Deepchecks and ZenML"
---

<ul id=""><li id="">Seamlessly integrate Deepchecks tests into ZenML pipelines using pre-built steps</li><li id="">Automatically validate data integrity, detect data drift, evaluate models and compare model performance</li><li id="">Visualize interactive test results and reports directly in ZenML artifacts and dashboard</li><li id="">Implement test result based branching and error handling for more robust pipelines</li><li id="">Switch between different levels of integration to maximize flexibility</li></ul>

‍<ul id=""><li id="">Extensive library of pre-configured data validation and model evaluation tests</li><li id="">Supports both tabular data and computer vision use cases</li><li id="">Smart defaults allow running test suites with minimal configuration</li><li id="">Fully customizable test conditions and validation logic</li><li id="">Generates interactive visual reports for easier analysis and sharing</li></ul>

‍<div data-rt-embed-type="true"><pre><code fs-codehighlight-element="code" class="language-python">
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.base import ClassifierMixin
from sklearn.ensemble import RandomForestClassifier

from zenml import pipeline, step
from zenml.integrations.constants import DEEPCHECKS, SKLEARN

from deepchecks.tabular.datasets.classification import iris
from typing_extensions import Tuple, Annotated

from zenml.artifacts.artifact_config import ArtifactConfig

LABEL_COL = "target"

@step
def data_loader() -&gt; Tuple[
 &nbsp; &nbsp;Annotated[
 &nbsp; &nbsp; &nbsp; &nbsp;pd.DataFrame, ArtifactConfig(name="reference_dataset")
 &nbsp; &nbsp;],
 &nbsp; &nbsp;Annotated[
 &nbsp; &nbsp; &nbsp; &nbsp;pd.DataFrame,
 &nbsp; &nbsp; &nbsp; &nbsp;ArtifactConfig(name="comparison_dataset"),
 &nbsp; &nbsp;],
]:
 &nbsp; &nbsp;"""Load the iris dataset."""
 &nbsp; &nbsp;iris_df = iris.load_data(data_format="Dataframe", as_train_test=False)
 &nbsp; &nbsp;df_train, df_test = train_test_split(
 &nbsp; &nbsp; &nbsp; &nbsp;iris_df, stratify=iris_df[LABEL_COL], random_state=0
 &nbsp; &nbsp;)
 &nbsp; &nbsp;return df_train, df_test

@step
def trainer(df_train: pd.DataFrame) -&gt; Annotated[ClassifierMixin, ArtifactConfig(name="model")]:
 &nbsp; &nbsp;# Train Model
 &nbsp; &nbsp;rf_clf = RandomForestClassifier(random_state=0)
 &nbsp; &nbsp;rf_clf.fit(df_train.drop(LABEL_COL, axis=1), df_train[LABEL_COL])
 &nbsp; &nbsp;return rf_clf

from zenml.integrations.deepchecks.steps import (
 &nbsp; &nbsp;deepchecks_data_integrity_check_step,
)

data_validator = deepchecks_data_integrity_check_step.with_options(
 &nbsp; &nbsp;parameters=dict(
 &nbsp; &nbsp; &nbsp; &nbsp;dataset_kwargs=dict(label=LABEL_COL, cat_features=[]),
 &nbsp; &nbsp;),
)

from zenml.integrations.deepchecks.steps import (
 &nbsp; &nbsp;deepchecks_data_drift_check_step,
)

data_drift_detector = deepchecks_data_drift_check_step.with_options(
 &nbsp; &nbsp;parameters=dict(dataset_kwargs=dict(label=LABEL_COL, cat_features=[]))
)

from zenml.integrations.deepchecks.steps import (
 &nbsp; &nbsp;deepchecks_model_validation_check_step,
)

model_validator = deepchecks_model_validation_check_step.with_options(
 &nbsp; &nbsp;parameters=dict(
 &nbsp; &nbsp; &nbsp; &nbsp;dataset_kwargs=dict(label=LABEL_COL, cat_features=[]),
 &nbsp; &nbsp;),
)

from zenml.integrations.deepchecks.steps import (
 &nbsp; &nbsp;deepchecks_model_drift_check_step,
)

model_drift_detector = deepchecks_model_drift_check_step.with_options(
 &nbsp; &nbsp;parameters=dict(
 &nbsp; &nbsp; &nbsp; &nbsp;dataset_kwargs=dict(label=LABEL_COL, cat_features=[]),
 &nbsp; &nbsp;),
)

from zenml.config import DockerSettings
docker_settings = DockerSettings(required_integrations=[DEEPCHECKS, SKLEARN])

@pipeline(enable_cache=True, settings={"docker": docker_settings})
def data_validation_pipeline():
 &nbsp; &nbsp;"""Links all the steps together in a pipeline"""
 &nbsp; &nbsp;df_train, df_test = data_loader()
 &nbsp; &nbsp;data_validator(dataset=df_train)
 &nbsp; &nbsp;data_drift_detector(
 &nbsp; &nbsp; &nbsp; &nbsp;reference_dataset=df_train,
 &nbsp; &nbsp; &nbsp; &nbsp;target_dataset=df_test,
 &nbsp; &nbsp;)
 &nbsp; &nbsp;model = trainer(df_train)
 &nbsp; &nbsp;model_validator(dataset=df_train, model=model)
 &nbsp; &nbsp;model_drift_detector(
 &nbsp; &nbsp; &nbsp; &nbsp;reference_dataset=df_train, target_dataset=df_test, model=model
 &nbsp; &nbsp;)


if __name__ == "__main__":
 &nbsp; &nbsp;# Run the pipeline
 &nbsp; &nbsp;data_validation_pipeline()
 &nbsp; &nbsp;
 &nbsp; &nbsp;</code></pre></div>In the code above, Deepchecks is integrated with ZenML to perform various data validation and model validation checks. The **data_loader** step loads the Iris dataset and splits it into training and testing sets. The **trainer** step trains a RandomForestClassifier on the training data. The **deepchecks_data_integrity_check_step** is used to validate the integrity of the training data, while the **deepchecks_data_drift_check_step** detects any data drift between the training and testing datasets. The **deepchecks_model_validation_check_step** validates the trained model on the training data, and the **deepchecks_model_drift_check_step** checks for model drift between the training and testing datasets. These steps are linked together in a ZenML pipeline, which is configured to use Docker settings for the required integrations. This setup ensures comprehensive data and model validation using Deepchecks within a ZenML pipeline.