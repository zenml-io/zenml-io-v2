---
title: "Lightning AI"
slug: "lightning-ai"
draft: false
webflow:
  siteId: "64a817a2e7e2208272d1ce30"
  itemId: "66e7f09f23216d0baea27187"
  exportedAt: "2026-02-11T10:23:34.071Z"
  source: "live"
  lastPublished: "2024-10-22T12:54:05.951Z"
  lastUpdated: "2024-10-15T10:33:54.929Z"
  createdOn: "2024-09-16T08:47:27.653Z"
integrationType: "orchestrator"
logo:
  url: "https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/4a361b85/66e7e9e24447135c7c269f29_Lightning_AI_Logo.jpeg"
shortDescription: "Accelerate and simplify model training with Lightning AI Studio and ZenML"
docsUrl: "https://docs.zenml.io/stack-components/orchestrators/lightning"
githubUrl: "https://lightning.ai/docs/"
mainImage:
  url: "https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/d21d0f70/670e4506e05e18c255ec5f86_Integration_image__6_.png"
seo:
  title: "Integrate Lightning AI with ZenML - Orchestrator Integrations"
  description: "Accelerate and simplify model training with Lightning AI Studio and ZenML"
  canonical: "https://www.zenml.io/integrations/lightning-ai"
  ogImage: "https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/d21d0f70/670e4506e05e18c255ec5f86_Integration_image__6_.png"
  ogTitle: "Integrate Lightning AI with ZenML - Orchestrator Integrations"
  ogDescription: "Accelerate and simplify model training with Lightning AI Studio and ZenML"
---

<ul id=""><li id=""><strong id="">Faster Execution:</strong> Automatic packaging and upload of code to your Lightning AI Studio.</li><li id=""><strong id="">Reproducible Training</strong>: Ensure consistent training results by encapsulating Lightning AI configurations within ZenML pipelines.</li><li id=""><strong id="">Quick Experimentation:</strong> Using ZenML’s configurable pipelines, you can run experiments with different parameters and on different machines quickly.</li><li id=""><strong id="">Seamless Tracking</strong>: Track and compare model metrics, hyperparameters, and artifacts using ZenML's experiment tracking features.</li></ul>

‍<ul id=""><li id="">Managed infrastructure, including GPUs, for running your pipelines.</li><li id="">Deployment of models supported.</li><li id="">Built-in support for distributed training.</li><li id="">Easy scaling of workloads on Lightning AI’s infrastructure.</li></ul>

‍You have to first set up your stack to include a Lightning AI orchestrator. Run the following commands after replacing the values with your own.

<div data-rt-embed-type="true"><pre><code fs-codehighlight-element="code" class="language-shell">zenml orchestrator register lightning_orchestrator \
 &nbsp; &nbsp;--flavor=lightning \
 &nbsp; &nbsp;--user_id=&lt;YOUR_LIGHTNING_USER_ID&gt; \
 &nbsp; &nbsp;--api_key=&lt;YOUR_LIGHTNING_API_KEY&gt; \
 &nbsp; &nbsp;--username=&lt;YOUR_LIGHTNING_USERNAME&gt; \
 &nbsp; &nbsp;--teamspace=&lt;YOUR_LIGHTNING_TEAMSPACE&gt; \
 &nbsp; &nbsp;--organization=&lt;YOUR_LIGHTNING_ORGANIZATION&gt;

# Register and activate a stack with the new orchestrator
zenml stack register lightning_stack -o lightning_orchestrator ... --set</code></pre></div>

You can also define settings inside your pipeline code and pass it to the settings parameter of your pipeline. Find out all the values you can set [from our code docs.](https://sdkdocs.zenml.io/latest/integration_code_docs/integrations-lightning/#zenml.integrations.lightning.flavors.lightning_orchestrator_flavor.LightningOrchestratorSettings)

<div data-rt-embed-type="true"><pre><code fs-codehighlight-element="code" class="language-shell">from zenml import pipeline, step
from zenml.integrations.lightning.flavors.lightning_orchestrator_flavor import (
 &nbsp; &nbsp;LightningOrchestratorSettings,
)

lightning_settings = LightningOrchestratorSettings(
 &nbsp; &nbsp;main_studio_name="my_studio", &nbsp;# change this to your studio name if you already have one
 &nbsp; &nbsp;machine_type="cpu",
 &nbsp; &nbsp;async_mode=True,
 &nbsp; &nbsp;custom_commands=["pip install -r requirements.txt"],
)


@step
def load_data() -&gt; dict:
 &nbsp; &nbsp;"""Simulates loading of training data and labels."""

 &nbsp; &nbsp;training_data = [[1, 2], [3, 4], [5, 6]]
 &nbsp; &nbsp;labels = [0, 1, 0]

 &nbsp; &nbsp;return {"features": training_data, "labels": labels}


@step
def train_model(data: dict) -&gt; None:
 &nbsp; &nbsp;"""
 &nbsp; &nbsp;A mock 'training' process that also demonstrates using the input data.
 &nbsp; &nbsp;In a real-world scenario, this would be replaced with actual model fitting logic.
 &nbsp; &nbsp;"""
 &nbsp; &nbsp;total_features = sum(map(sum, data["features"]))
 &nbsp; &nbsp;total_labels = sum(data["labels"])

 &nbsp; &nbsp;print(
 &nbsp; &nbsp; &nbsp; &nbsp;f"Trained model using {len(data['features'])} data points. "
 &nbsp; &nbsp; &nbsp; &nbsp;f"Feature sum is {total_features}, label sum is {total_labels}"
 &nbsp; &nbsp;)


@pipeline(settings={"orchestrator": lightning_settings})
def simple_ml_pipeline():
 &nbsp; &nbsp;"""Define a pipeline that connects the steps."""
 &nbsp; &nbsp;dataset = load_data()
 &nbsp; &nbsp;train_model(dataset)


if __name__ == "__main__":
 &nbsp; &nbsp;run = simple_ml_pipeline()
 &nbsp; &nbsp;# You can now use the `run` object to see steps, outputs, etc.</code></pre></div>The code example demonstrates running a simple pipeline with the Lightning AI orchestrator. You can see that we set a studio name explicitly; ZenML creates one for you if you leave it empty. We can also configure a host of other options in the settings. In the snippet above, we have added the settings directly in code but you can also [use YAML files](https://docs.zenml.io/how-to/use-configuration-files) to keep the code and configuration separate, allowing you to run the same piece of code with multiple configs.