---
title: "Google Cloud Vertex AI Pipelines"
slug: "gcp-vertexai"
draft: false
webflow:
  siteId: "64a817a2e7e2208272d1ce30"
  itemId: "6527b8aa8b6c10a93e045e28"
  exportedAt: "2026-02-11T10:23:34.071Z"
  source: "live"
  lastPublished: "2024-10-22T12:54:05.951Z"
  lastUpdated: "2024-10-15T10:55:41.255Z"
  createdOn: "2023-10-12T09:13:14.382Z"
integrationType: "orchestrator"
logo:
  url: "https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/3621e87c/66d86886a6dc58ed59b15d41_vertex.png"
shortDescription: "Streamline your MLOps workflows on GCP with ZenML and Vertex AI Pipelines"
docsUrl: "https://docs.zenml.io/stack-components/orchestrators/vertex"
mainImage:
  url: "https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/e0ff5439/66e7310b0dcb8cb0f1d0050a_image__9_.png"
relatedBlogPosts:
  - "cloud-composer-airflow-vs-vertex-ai-kubeflow"
  - "easy-mlops-pipelines"
  - "building-scalable-forecasting-solutions"
seo:
  title: "Integrate Google Cloud Vertex AI Pipelines with ZenML - Orchestrator Integrations"
  description: "Streamline your MLOps workflows on GCP with ZenML and Vertex AI Pipelines"
  canonical: "https://www.zenml.io/integrations/gcp-vertexai"
  ogImage: "https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/e0ff5439/66e7310b0dcb8cb0f1d0050a_image__9_.png"
  ogTitle: "Integrate Google Cloud Vertex AI Pipelines with ZenML - Orchestrator Integrations"
  ogDescription: "Streamline your MLOps workflows on GCP with ZenML and Vertex AI Pipelines"
---

<ul id=""><li id="">Seamlessly integrate ZenML pipelines with Vertex AI Pipelines for end-to-end ML workflows on GCP</li><li id="">Easily deploy and scale your pipelines using Vertex AI's managed serverless infrastructure</li><li id="">Track and monitor pipeline runs through the intuitive Vertex AI UI, accessible directly from ZenML</li><li id="">Leverage GPU acceleration for compute-intensive steps in your ZenML pipelines</li><li id="">Schedule recurring pipeline runs using Vertex AI's native scheduling capabilities</li></ul>

‍<ul id=""><li id="">Fully managed serverless infrastructure for running ML pipelines at scale</li><li id="">Intuitive UI for visualizing and monitoring pipeline runs and logs</li><li id="">Native support for GPU-accelerated workloads</li><li id="">Flexible scheduling options for recurring pipeline runs</li><li id="">Seamless integration with other GCP services and tools in the Vertex AI platform</li></ul>

‍<div data-rt-embed-type="true"><pre><code fs-codehighlight-element="code" class="language-shell">
zenml integration install gcp
zenml stack set ...
</code></pre></div>

<div data-rt-embed-type="true"><pre><code fs-codehighlight-element="code" class="language-python">
from zenml.integrations.gcp.flavors.vertex_orchestrator_flavor import VertexOrchestratorSettings

# Choose an accelerator to run on
vertex_settings = VertexOrchestratorSettings(
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;node_selector_constraint=(
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"cloud.google.com/gke-accelerator",
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"NVIDIA_TESLA_P4",
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;)
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;)

@pipeline(
 &nbsp; &nbsp;settings={
 &nbsp; &nbsp; &nbsp; &nbsp;"orchestrator.vertex": vertex_settings,
 &nbsp; &nbsp;}
)
def vertex_pipeline():
 &nbsp; &nbsp;ingest_data()
 &nbsp; &nbsp;train_model()
 &nbsp; &nbsp;evaluate_model()

# Run the pipeline
vertex_pipeline()
</code></pre></div>This code snippet demonstrates how to configure a ZenML pipeline to run on Vertex AI Pipelines. The VertexOrchestratorSettings allows you to specify settings and other settings for the Vertex AI job. The pipeline steps are defined as usual, and the pipeline is run by calling vertex_pipeline().