---
title: "LlamaIndex"
slug: "llamaindex"
draft: false
webflow:
  siteId: "64a817a2e7e2208272d1ce30"
  itemId: "68adc2ae2834158a0f6e081e"
  exportedAt: "2026-02-11T10:23:34.071Z"
  source: "live"
  lastPublished: "2025-08-26T14:51:22.115Z"
  lastUpdated: "2025-08-26T14:25:09.690Z"
  createdOn: "2025-08-26T14:20:30.481Z"
integrationType: "agents"
logo:
  url: "https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/dc393543/68adc2b39206458c0cbe525e_llamaindex.png"
shortDescription: "LlamaIndex Function Agent integrated with ZenML"
docsUrl: "https://docs.zenml.io"
githubUrl: "https://github.com/zenml-io/zenml/tree/main/examples/agent_framework_integrations/langgraph"
mainImage:
  url: "https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/da7c121c/68adc3b0a9eaacaf244b9b63_llamaindex.img.png"
relatedBlogPosts:
  - "llamaindex-vs-langgraph"
  - "llamaindex-pricing"
seo:
  title: "Integrate LlamaIndex with ZenML - Agents Integrations"
  description: "LlamaIndex Function Agent integrated with ZenML"
  canonical: "https://www.zenml.io/integrations/llamaindex"
  ogImage: "https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/da7c121c/68adc3b0a9eaacaf244b9b63_llamaindex.img.png"
  ogTitle: "Integrate LlamaIndex with ZenML - Agents Integrations"
  ogDescription: "LlamaIndex Function Agent integrated with ZenML"
---

<ul id=""><li id=""><strong id="">Async-friendly orchestration.</strong> Run LlamaIndex function agents that require awaiting inside ZenML steps without changing agent code.</li><li id="">‍<strong id="">Tool call lineage.</strong> Track queries, intermediate tool outputs, and final responses as versioned artifacts.</li><li id="">‍<strong id="">Composable pipelines.</strong> Chain agents with retrieval, evals, and deployment in one DAG.</li><li id="">‍<strong id="">Evaluation ready.</strong> Add post-run checks to score response quality, latency, and tool accuracy.</li><li id="">‍<strong id="">Portable execution.</strong> Move the same pipeline from local runs to Kubernetes or Airflow via ZenML stacks.</li></ul><ul id=""><li id=""><strong id="">Function agents.</strong> Define agents that call Python tools to solve tasks.</li><li id="">‍<strong id="">Async execution.</strong> Properly await <code id="">agent.run(...)</code> for non-blocking workflows.</li><li id="">‍<strong id="">Multiple tools.</strong> Plug in weather, tip calculator, and custom utilities.</li></ul><div data-rt-embed-type="true"><pre><code fs-codehighlight-element="code">from zenml import ExternalArtifact, pipeline, step
from agent import agent  # LlamaIndex function agent with tools

@step
def run_llamaindex(query: str) -&gt; str:
   # LlamaIndex agent.run is async; await it inside the step
   import asyncio
   async def _run():
       return await agent.run(query)
   resp = asyncio.run(_run())
   return str(getattr(resp, "response", resp))

@pipeline
def llamaindex_agent_pipeline() -&gt; str:
   q = ExternalArtifact(
       value="What's the weather in New York and calculate a 15% tip for $50?"
   )
   return run_llamaindex(q.value)

if __name__ == "__main__":
   print(llamaindex_agent_pipeline())</code></pre></div>