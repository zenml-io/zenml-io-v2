---
title: "Weights & Biases"
slug: "wandb"
draft: false
webflow:
  siteId: "64a817a2e7e2208272d1ce30"
  itemId: "6527b8a902d77560c9f7f2ad"
  exportedAt: "2026-02-11T10:23:34.071Z"
  source: "live"
  lastPublished: "2024-10-08T06:36:37.844Z"
  lastUpdated: "2024-10-08T06:36:37.844Z"
  createdOn: "2023-10-12T09:13:13.415Z"
integrationType: "experiment-tracker"
logo:
  url: "https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/d15ff444/66d869126dc9da65a47f4a58_wandb.png"
shortDescription: "Supercharge your ZenML pipelines with seamless Weights & Biases experiment tracking and visualization"
docsUrl: "https://docs.zenml.io/stack-components/experiment-trackers/wandb"
githubUrl: "https://docs.zenml.io/stack-components/experiment-trackers/wandb"
mainImage:
  url: "https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/f38cc2ca/66f1609c09b07cedd8e525e5_Integration_image__3_.png"
seo:
  title: "Integrate Weights & Biases with ZenML - Experiment Tracker Integrations"
  description: "Supercharge your ZenML pipelines with seamless Weights & Biases experiment tracking and visualization"
  canonical: "https://www.zenml.io/integrations/wandb"
  ogImage: "https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/f38cc2ca/66f1609c09b07cedd8e525e5_Integration_image__3_.png"
  ogTitle: "Integrate Weights & Biases with ZenML - Experiment Tracker Integrations"
  ogDescription: "Supercharge your ZenML pipelines with seamless Weights & Biases experiment tracking and visualization"
---

<ul id=""><li id="">Seamlessly log models, parameters, and metrics from ZenML pipeline steps</li><li id="">Visualize and compare pipeline run results in the intuitive Weights &amp; Biases UI</li><li id="">Share pipeline artifacts and performance with team members and stakeholders</li><li id="">Maintain experiment tracking continuity as you transition to MLOps best practices with ZenML</li></ul>

‍<ul id=""><li id="">Comprehensive experiment tracking and logging</li><li id="">Interactive visualization of models, datasets, and results</li><li id="">Collaboration features for sharing and discussing ML experiments</li><li id="">Integrations with popular ML frameworks and tools</li><li id="">Powerful querying and comparison of runs across projects</li></ul>

‍

‍<div data-rt-embed-type="true"><pre><code fs-codehighlight-element="code" class="language-python">from typing import Tuple
from zenml import pipeline, step
from zenml.client import Client
from zenml.integrations.wandb.flavors.wandb_experiment_tracker_flavor import (
 &nbsp; &nbsp;WandbExperimentTrackerSettings,
)
from transformers import (
 &nbsp; &nbsp;AutoModelForSequenceClassification,
 &nbsp; &nbsp;AutoTokenizer,
 &nbsp; &nbsp;Trainer,
 &nbsp; &nbsp;TrainingArguments,
 &nbsp; &nbsp;DistilBertForSequenceClassification,
)
from datasets import load_dataset, Dataset
import numpy as np
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
import wandb

# Get the experiment tracker from the active stack
experiment_tracker = Client().active_stack.experiment_tracker


@step
def prepare_data() -&gt; Tuple[Dataset, Dataset]:
 &nbsp; &nbsp;dataset = load_dataset("imdb")
 &nbsp; &nbsp;tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")
 &nbsp; &nbsp;def tokenize_function(examples):
 &nbsp; &nbsp; &nbsp; &nbsp;return tokenizer(examples["text"], padding="max_length", truncation=True)
 &nbsp; &nbsp;tokenized_datasets = dataset.map(tokenize_function, batched=True)
 &nbsp; &nbsp;return (
 &nbsp; &nbsp; &nbsp; &nbsp;tokenized_datasets["train"].shuffle(seed=42).select(range(1000)),
 &nbsp; &nbsp; &nbsp; &nbsp;tokenized_datasets["test"].shuffle(seed=42).select(range(100)),
 &nbsp; &nbsp;)


@step(experiment_tracker=experiment_tracker.name)
def train_model(
 &nbsp; &nbsp;train_dataset: Dataset, eval_dataset: Dataset
) -&gt; DistilBertForSequenceClassification:
 &nbsp; &nbsp;model = AutoModelForSequenceClassification.from_pretrained(
 &nbsp; &nbsp; &nbsp; &nbsp;"distilbert-base-uncased", num_labels=2
 &nbsp; &nbsp;)
 &nbsp; &nbsp;training_args = TrainingArguments(
 &nbsp; &nbsp; &nbsp; &nbsp;output_dir="./results",
 &nbsp; &nbsp; &nbsp; &nbsp;num_train_epochs=3,
 &nbsp; &nbsp; &nbsp; &nbsp;per_device_train_batch_size=16,
 &nbsp; &nbsp; &nbsp; &nbsp;per_device_eval_batch_size=16,
 &nbsp; &nbsp; &nbsp; &nbsp;report_to=["wandb"],
 &nbsp; &nbsp;)

 &nbsp; &nbsp;def compute_metrics(eval_pred):
 &nbsp; &nbsp; &nbsp; &nbsp;logits, labels = eval_pred
 &nbsp; &nbsp; &nbsp; &nbsp;predictions = np.argmax(logits, axis=-1)
 &nbsp; &nbsp; &nbsp; &nbsp;precision, recall, f1, _ = precision_recall_fscore_support(
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;labels, predictions, average="binary"
 &nbsp; &nbsp; &nbsp; &nbsp;)
 &nbsp; &nbsp; &nbsp; &nbsp;acc = accuracy_score(labels, predictions)
 &nbsp; &nbsp; &nbsp; &nbsp;return {"accuracy": acc, "f1": f1, "precision": precision, "recall": recall}

 &nbsp; &nbsp;trainer = Trainer(
 &nbsp; &nbsp; &nbsp; &nbsp;model=model,
 &nbsp; &nbsp; &nbsp; &nbsp;args=training_args,
 &nbsp; &nbsp; &nbsp; &nbsp;train_dataset=train_dataset,
 &nbsp; &nbsp; &nbsp; &nbsp;eval_dataset=eval_dataset,
 &nbsp; &nbsp; &nbsp; &nbsp;compute_metrics=compute_metrics,
 &nbsp; &nbsp;)

 &nbsp; &nbsp;trainer.train()

 &nbsp; &nbsp;# Evaluate the model
 &nbsp; &nbsp;eval_results = trainer.evaluate()
 &nbsp; &nbsp;print(f"Evaluation results: {eval_results}")

 &nbsp; &nbsp;# Log final evaluation results
 &nbsp; &nbsp;wandb.log({"final_evaluation": eval_results})

 &nbsp; &nbsp;return model


@pipeline
def fine_tuning_pipeline():
 &nbsp; &nbsp;train_dataset, eval_dataset = prepare_data()
 &nbsp; &nbsp;model = train_model(train_dataset, eval_dataset)


if __name__ == "__main__":
 &nbsp; &nbsp;# Run the pipeline
 &nbsp; &nbsp;wandb_settings = WandbExperimentTrackerSettings(
 &nbsp; &nbsp; &nbsp; &nbsp;tags=["distilbert", "imdb", "sentiment-analysis"],
 &nbsp; &nbsp;)

 &nbsp; &nbsp;fine_tuning_pipeline.with_options(settings={"experiment_tracker": wandb_settings})()</code></pre></div>

‍This code snippet demonstrates how to enable Weights & Biases experiment tracking in a ZenML pipeline step using the @step decorator. Inside the step, the WandbCallback is used to log evaluation metrics during model training, and wandb.log is called to manually log a validation metric. The Weights & Biases experiment tracker is configured through the "wandb_tracker" stack component.