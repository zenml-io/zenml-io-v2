---
title: "Databricks"
slug: "databricks"
draft: false
webflow:
  siteId: "64a817a2e7e2208272d1ce30"
  itemId: "6696381da0239dc526233175"
  exportedAt: "2026-02-11T10:23:34.071Z"
  source: "live"
  lastPublished: "2024-09-23T10:17:28.536Z"
  lastUpdated: "2024-09-23T10:17:28.536Z"
  createdOn: "2024-07-16T09:06:37.633Z"
integrationType: "orchestrator"
logo:
  url: "https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/5439fa99/6696392a47017a8a18c7fb7e_Databricks_logo.png"
shortDescription: "Harness the Power of Databricks for Scalable ML Pipelines with ZenML"
docsUrl: "https://docs.zenml.io/stack-components/orchestrators/databricks"
githubUrl: "https://github.com/zenml-io/zenml-projects/tree/main/databricks-demo"
mainImage:
  url: "https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/5fc719b5/66ed5712f4a21172a9e148d4_image__27_.png"
relatedBlogPosts:
  - "using-zenml-databricks-to-supercharge-llm-development"
seo:
  title: "Integrate Databricks with ZenML - Orchestrator Integrations"
  description: "Harness the Power of Databricks for Scalable ML Pipelines with ZenML"
  canonical: "https://www.zenml.io/integrations/databricks"
  ogImage: "https://pub-d0f853843b954aadbcd60eaff1d9c6e2.r2.dev/webflow/64a817a2e7e2208272d1ce30/5fc719b5/66ed5712f4a21172a9e148d4_image__27_.png"
  ogTitle: "Integrate Databricks with ZenML - Orchestrator Integrations"
  ogDescription: "Harness the Power of Databricks for Scalable ML Pipelines with ZenML"
---

<ul id=""><li id="">Effortlessly orchestrate ZenML pipelines on Databricks infrastructure</li><li id="">Leverage Databricks' distributed computing power for large-scale ML tasks</li><li id="">Seamlessly integrate with other Databricks services and tools</li><li id="">Monitor and manage pipeline runs through the Databricks UI</li><li id="">Schedule pipelines using Databricks' native scheduling capabilities</li></ul>

‍<ul id=""><li id="">Optimized for big data processing and machine learning workloads</li><li id="">Collaborative environment for data scientists, engineers, and analysts</li><li id="">Scalable and high-performance distributed computing</li><li id="">Integrated with popular data and ML frameworks (e.g., Spark, TensorFlow, PyTorch)</li><li id="">Comprehensive security and governance features</li></ul>

‍<div data-rt-embed-type="true"><pre><code fs-codehighlight-element="code" class="language-python">
from zenml.integrations.databricks.flavors.databricks_orchestrator_flavor import DatabricksOrchestratorSettings

databricks_settings = DatabricksOrchestratorSettings(
 &nbsp; &nbsp;spark_version="15.3.x-scala2.12",
 &nbsp; &nbsp;num_workers="3",
 &nbsp; &nbsp;node_type_id="Standard_D4s_v5",
 &nbsp; &nbsp;policy_id=POLICY_ID,
 &nbsp; &nbsp;autoscale=(2, 3),
)

@pipeline(
 &nbsp; &nbsp;settings={
 &nbsp; &nbsp; &nbsp; &nbsp;"orchestrator.databricks": databricks_settings,
 &nbsp; &nbsp;}
)
def my_pipeline():
 &nbsp; &nbsp;load_data()
 &nbsp; &nbsp;preprocess_data()
 &nbsp; &nbsp;train_model()
 &nbsp; &nbsp;evaluate_model()

my_pipeline().run()
</code></pre></div>This code example demonstrates how to configure the Databricks orchestrator settings in ZenML. The DatabricksOrchestratorSettings object is used to specify the Spark version, number of workers, node type, autoscaling settings, and other configuration options. These settings are then passed to the @pipeline decorator using the settings parameter. Finally, the pipeline is defined with its steps and executed using my_pipeline().run().